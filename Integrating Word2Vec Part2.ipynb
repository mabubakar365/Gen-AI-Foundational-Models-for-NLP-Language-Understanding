{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPJTjvtPs8q+FqeAb7e7vLs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Integrating Word2Vec Part2**\n"],"metadata":{"id":"gCQzrLoujYyl"}},{"cell_type":"markdown","source":["This lab continues from **Integrating Word2Vec Part 1**, where you explored Skip-gram and CBOW models, learning how to build and apply them for text classification in PyTorch. You also integrated pretrained GloVe embeddings to enhance the models.\n","\n","In this lab, an optional section on advanced embedding applications is available for further exploration. By the end, you will have gained proficiency in leveraging word embeddings for various natural language processing (NLP) tasks.\n"],"metadata":{"id":"C85IRJFojco6"}},{"cell_type":"markdown","source":["## __Table of Contents__\n","\n","<ol>\n","    <li><a href=\"#Objectives\">Objectives</a></li>\n","    <li>\n","        <a href=\"#Setup\">Setup</a>\n","        <ol>\n","            <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n","            <li><a href=\"#Importing-Required-Libraries\">Importing required libraries</a></li>\n","        </ol>\n","    </li>\n","    <li>\n","        <a href=\"#Background\">Background</a>\n","        <ol>\n","            <li><a href=\"#GloVe-(Optional)\">GloVe (Optional)</a></li>\n","        </ol>\n","    </li>\n","    <li>\n","            <a href=\"#Applying-pretrained-word-embeddings-(optional)\">Applying pretrained word embeddings (optional)</a>\n","        <ol>\n","            <li><a href=\"#Load-Stanford-GloVe-model\">Load Stanford GloVe model</a></li>\n","            <li><a href=\"#Train-a-word2vec-model-from-gensim\">Train a word2vec model from gensim</a></li>\n","        </ol>\n","    </li>\n","    <li><a href=\"#Text-classification-using-pretrained-word-embeddings\">Text classification using pretrained word embeddings</a></li>\n","</ol>\n","\n"],"metadata":{"id":"NI2eFml9jkoU"}},{"cell_type":"markdown","source":["## Objectives\n","\n","After completing this lab you will be able to:\n","- Get pretrained large embedding models and generate word embeddings with them.\n","- Train a word2vec model on a domain-specific data.\n"],"metadata":{"id":"lkQBLyoLjnHe"}},{"cell_type":"markdown","source":["## Setup\n"],"metadata":{"id":"uuz0QmDijwVZ"}},{"cell_type":"markdown","source":["For this lab, you will be using the following libraries:\n","\n","*   [`torch`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for building NN models and preparing the data.\n","*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n","*   [`gensim`](https://pypi.org/project/gensim/) for word2vec pretrained models.\n","*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n","*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n"],"metadata":{"id":"Od58MmkxjudV"}},{"cell_type":"markdown","source":["### Installing required libraries\n"],"metadata":{"id":"hW9M5_7Ojye7"}},{"cell_type":"markdown","source":["This script defines a **utility function**, **\"find_similar_words\"**, to identify words most similar to a given target word using word embeddings. It computes cosine similarity between word vectors to find the closest matches. This helps in NLP tasks like synonym discovery, word clustering, and semantic analysis.\n"],"metadata":{"id":"uYhCaDj6j7gH"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"_ZD-V2d0jWwF","executionInfo":{"status":"ok","timestamp":1753736162553,"user_tz":420,"elapsed":21,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"outputs":[],"source":["import numpy as np\n","\n","def find_similar_words(target_word, embedding_dict, top_k=2):\n","  if target_word not in embedding_dict:\n","    return f\"{target_word} not found in embeddings.\"\n","\n","  print(target_word)\n","\n","  target_vector = embedding_dict[target_word]\n","  similarities = {}\n","\n","  for word, vector in embedding_dict.items():\n","    if word == target_word:\n","      continue\n","      print(word)\n","      similarity = np.dot(target_vector, vector)/(np.linalg.norm(target_vector) * np.linalg.norm(vector))\n","      similarities[word] = similarity\n","\n","  sorted_words = sorted(similarities.items(), key = lambda x: x[1], reverse=True)\n","\n","  return [word for word, _ in sorted_words[:top_k]]\n"]},{"cell_type":"code","source":["!pip install numpy==1.26.4\n","!pip install seaborn\n","!pip install matplotlib\n","!pip install scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8xweq1llXec","executionInfo":{"status":"ok","timestamp":1753736230192,"user_tz":420,"elapsed":21711,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"28e3dd9a-222c-49b8-cd21-2558dc19c8e4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"]}]},{"cell_type":"code","source":["!pip install gensim\n","!pip install portalocker>=2.0.0\n","!pip install torch==2.2.2\n","!pip install torchdata==0.7.1\n","!pip install torchtext==0.17.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xRdOmeSloSx","executionInfo":{"status":"ok","timestamp":1753736476781,"user_tz":420,"elapsed":223956,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"1c32aa1e-d7f7-4ee7-ed56-c10eb00ea122"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n","Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n","  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n","Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scipy, gensim\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.16.0\n","    Uninstalling scipy-1.16.0:\n","      Successfully uninstalled scipy-1.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gensim-4.3.3 scipy-1.13.1\n","Collecting torch==2.2.2\n","  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.2.0 (from torch==2.2.2)\n","  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.2) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n","Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n","torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 triton-2.2.0\n","Collecting torchdata==0.7.1\n","  Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1) (2.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1) (2.32.3)\n","Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1) (2.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.7.1) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata==0.7.1) (12.5.82)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.7.1) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.7.1) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.7.1) (2025.7.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata==0.7.1) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2->torchdata==0.7.1) (1.3.0)\n","Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torchdata\n","  Attempting uninstall: torchdata\n","    Found existing installation: torchdata 0.11.0\n","    Uninstalling torchdata-0.11.0:\n","      Successfully uninstalled torchdata-0.11.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torchdata-0.7.1\n","Collecting torchtext==0.17.2\n","  Downloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.2) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.2) (2.32.3)\n","Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.2) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.2) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2->torchtext==0.17.2) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchtext==0.17.2) (12.5.82)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (2025.7.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.2->torchtext==0.17.2) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.2->torchtext==0.17.2) (1.3.0)\n","Downloading torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torchtext\n","Successfully installed torchtext-0.17.2\n"]}]},{"cell_type":"markdown","source":["### Importing required libraries\n","\n","_It is recommended that you import all required libraries in one place (here):_\n"],"metadata":{"id":"Nabv-EQjnCLP"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.manifold import TSNE\n","\n","from IPython.core.display import display, SVG\n","\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader, random_split\n","\n","import logging\n","from gensim.models import Word2Vec\n","from collections import defaultdict\n","\n","import torch\n","import torch.nn as nn\n","\n","import torch.optim as optim\n","from torchtext.vocab import GloVe,vocab\n","\n","from torchdata.datapipes.iter import IterableWrapper, Mapper\n","from torchtext.datasets import AG_NEWS\n","\n","from torchtext.data.functional import to_map_style_dataset\n","from torchtext.data.utils import get_tokenizer\n","from tqdm import tqdm\n","# from utils import find_similar_words\n","\n","%matplotlib inline\n","\n","def warn(*args, **kwargs):\n","  pass\n","\n","import warnings\n","warnings.warn = warn\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"-U2EHoE0mAWp","executionInfo":{"status":"ok","timestamp":1753739029870,"user_tz":420,"elapsed":88,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18x2BDGfosI0","executionInfo":{"status":"ok","timestamp":1753739030141,"user_tz":420,"elapsed":32,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"6b944dac-3031-42ae-80f8-49efa30f533b"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","source":["# Background\n","\n","In this lab session, you'll explore the GloVe model, and an **optional** summary is provided to enhance your understanding of its application in natural language processing.\n","## GloVe (Optional)\n","\n","\n","\n","GloVe, on the other hand, is another popular algorithm for learning word embeddings. It stands for Global Vectors for Word Representation. Unlike word2vec, which is based on predicting context/target words, GloVe focuses on capturing the global word co-occurrence statistics from the entire corpus. It constructs a co-occurrence matrix that represents how often words appear together in the text. The matrix is then factorized to obtain the word embeddings. For example, if \"Man\" and \"King\" co-occure many times, their vectors will be simialr.\n","\n","The GloVe model follows a fundamental approach by constructing a large word-context co-occurrence matrix that contains pairs of (word, context). Each entry in this matrix represents the frequency of a word occurring within a given context, which can be a sequence of words. The objective of the model is to utilize matrix factorization techniques to approximate this co-occurrence matrix. The process is illustrated in the following diagram:\n","\n","1. Create a word-context co-occurrence matrix: The model begins by generating a matrix that captures the co-occurrence information of words and their surrounding contexts. Each element in the matrix represents how often a specific word and context pair co-occur in the training data.\n","\n","2. Apply matrix factorization: Next, the GloVe model applies matrix factorization methods to approximate the word-context co-occurrence matrix. The goal is to decompose the original matrix into lower-dimensional representations that capture the semantic relationships between words and contexts.\n","\n","3. Obtain word and context embeddings: By factorizing the co-occurrence matrix, the model obtains word and context embeddings. These embeddings are numerical representations that encode the semantic meaning and relationships of words and contexts.\n","\n","To accomplish this, you can usually begin by initializing WF (Word-Feature matrix) and FC (Feature-Context matrix) with random weights.You will then perform a multiplication operation between these matrices to obtain WC' (an approximation of WC), and assess its similarity to WC. This process is repeated multiple times using Stochastic Gradient Descent (SGD) to minimize the error(WC'-WC).\n","\n","Once the training is complete, the resulting Word-Feature matrix (WF) provides you with word embeddings or vector representations for each word(the green vector in the diagram). The dimensionality of the embedding vectors can be predetermined by setting the value of F to a specific number of dimensions, allowing for a compact representation of the word semantics.\n","\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/matrix%20fact.png\" alt=\"Co-occurence matrix\" class=\"bg-primary\" width=\"600px\">\n","\n","The key advantage of GloVe is that it can incorporate both global statistics and local context information. This results in word embeddings that not only capture the semantic relationships between words but also preserve certain syntactic relationships.\n"],"metadata":{"id":"e31c2XLspUNh"}},{"cell_type":"markdown","source":["# Applying pretrained word embeddings (optional)\n","## Load Stanford GloVe model\n","\n","Transfer learning, particularly through the use of pretrained word embeddings, serves as a cornerstone in modern NLP. This approach leverages knowledge gleaned from one task, typically learned over massive datasets, and applies it to another, often more specialized task. The primary advantage of this is twofold: it bypasses the need for enormous computational resources to learn from scratch, and it injects a base layer of linguistic understanding into the model. By using embeddings that have already captured complex language patterns and associations, even models with limited exposure to domain-specific data can exhibit remarkably sophisticated behavior, making transfer learning a strategic shortcut to enhanced performance in NLP.\n"],"metadata":{"id":"do3hMCJIqUOb"}},{"cell_type":"markdown","source":["Let's take a look at the pretrained GloVe model from Stanford:\n"],"metadata":{"id":"iwOpa1a_qV7X"}},{"cell_type":"markdown","source":["You can specify the model name and embedding dimension: GloVe(name='GloVe_model_name', dim=300)\n"],"metadata":{"id":"NsP5PCEVqXcj"}},{"cell_type":"markdown","source":["In **Natural Language Processing (NLP)**, the **embedding dimension** refers to the size of the vector used to represent each word (or token) in a continuous vector space.\n","\n","---\n","\n","### 📌 What is a Word Embedding?\n","\n","Word embeddings are numerical representations of words, where **semantically similar words** have **similar vector representations**. For example:\n","\n","* \"king\" might be represented as `[0.3, 0.7, -0.2, ..., 0.1]`\n","* \"queen\" as `[0.4, 0.8, -0.1, ..., 0.2]`\n","\n","These vectors are learned from large text corpora and capture **syntactic and semantic meaning**.\n","\n","---\n","\n","### 📐 What is the Embedding Dimension?\n","\n","The **embedding dimension** is the **number of values in the vector** that represents each word.\n","\n","* Example: If you're using a 300-dimensional embedding, then each word is represented as a 300-length vector:\n","\n","  $$\n","  \\text{word vector} \\in \\mathbb{R}^{300}\n","  $$\n","\n","---\n","\n","### 🤔 Why Does Embedding Dimension Matter?\n","\n","* **Higher dimensions** → Can capture **more nuanced relationships** but:\n","\n","  * Need more data to train properly\n","  * More computationally expensive\n","  * Risk of overfitting\n","* **Lower dimensions** → Less expressive, but:\n","\n","  * Faster\n","  * Easier to generalize with less data\n","\n","---\n","\n","### 🔧 Typical Embedding Sizes\n","\n","* **GloVe**: 50, 100, 200, or 300 dimensions\n","* **Word2Vec**: 100–300 dimensions are common\n","* **BERT/Transformer models**:\n","\n","  * Embedding size is often 768 (base model) or 1024 (large model)\n","\n","---\n","\n","### ⚙️ Where It Appears in Practice\n","\n","In code (e.g., PyTorch or TensorFlow):\n","\n","```python\n","embedding_layer = nn.Embedding(num_embeddings=10000, embedding_dim=300)\n","```\n","\n","Here, `embedding_dim=300` sets the embedding dimension.\n","\n","---\n","\n","### 🔄 Summary\n","\n","| Term                | Meaning                                    |\n","| ------------------- | ------------------------------------------ |\n","| Embedding           | Vector representing a word or token        |\n","| Embedding Dimension | Number of elements in the vector           |\n","| Typical Range       | 50 to 1024 depending on model and use case |"],"metadata":{"id":"RAmI2XcwRzrI"}},{"cell_type":"code","source":["# creating an instance of the 6B version of Glove() model\n","glove_vectors_6B = GloVe(name='6B')"],"metadata":{"id":"vbp8DMjkpP2H","executionInfo":{"status":"ok","timestamp":1753739412700,"user_tz":420,"elapsed":2446,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":["You must continue with the 6B model as it is lighter. You can load different pretrained GloVe models from torch() using ```torch.nn.Embedding.from_pretrained```.\n"],"metadata":{"id":"TvvXdyTiSL86"}},{"cell_type":"markdown","source":["In the line:\n","\n","```python\n","embeddings_Glove6B = torch.nn.Embedding.from_pretrained(glove_vectors_6B.vectors, freeze=True)\n","```\n","\n","### 🔒 `freeze=True` means:\n","\n","The **embedding weights will not be updated** during training. They are **frozen**.\n","\n","---\n","\n","### ✅ Why use `freeze=True`?\n","\n","* You want to **keep the pretrained GloVe embeddings unchanged**.\n","* Prevents overwriting the semantic information they already contain.\n","* Useful when training data is limited or when the embeddings are already well-trained.\n","\n","---\n","\n","### 🔄 If `freeze=False`:\n","\n","* The embeddings are **fine-tuned** during training.\n","* Can help adapt them to a specific task, but might lose general semantic meaning if overtrained.\n"],"metadata":{"id":"7_RYlopMS-eh"}},{"cell_type":"markdown","source":["When you **freeze the embeddings**, **only the embedding layer’s weights stay constant**. The rest of the model (e.g., LSTM, Transformer, classifier layers) **can still be trained** and **will learn from the embeddings**.\n","\n","---\n","\n","### 🔁 What’s Actually Happening:\n","\n","* **Frozen embeddings**: Provide fixed, meaningful word representations from GloVe.\n","* **Trainable model layers**: Use these embeddings as input to learn how to solve the task (e.g., sentiment analysis, text classification, etc.)\n","\n","---\n","\n","### 🧠 Analogy:\n","\n","Think of frozen embeddings like using a **dictionary** — the word meanings are fixed. But your model is like a **student** using the dictionary to answer questions. The student (model) gets better with training, even though the dictionary (embeddings) doesn’t change.\n","\n","---\n","\n","### ✅ When to freeze embeddings:\n","\n","* When your dataset is **small** (avoids overfitting).\n","* When using **high-quality pretrained embeddings** like GloVe or fastText.\n","* When you care more about **general word meaning** than domain-specific nuances.\n","\n","---\n","\n","### 🔄 When not to freeze:\n","\n","* If your dataset is **large and domain-specific** (e.g., medical, legal text).\n","* If you want the embeddings to **adapt to the task**.\n","\n","---\n","\n","### Summary:\n","\n","| Layer           | Frozen?              | Learns? |\n","| --------------- | -------------------- | ------- |\n","| Embedding layer | ✅ (if `freeze=True`) | ❌       |\n","| Remaining model | ❌                    | ✅       |\n","\n","So training still happens — just **not in the embedding layer** if it's frozen.\n"],"metadata":{"id":"1ASqN1DnTCxM"}},{"cell_type":"code","source":["# load the glove model pretrained weights into a PyTorch embedding layer\n","embeddings_Glove6B = torch.nn.Embedding.from_pretrained(glove_vectors_6B.vectors, freeze=True)"],"metadata":{"id":"m2E1sxhuQ9Ni","executionInfo":{"status":"ok","timestamp":1753739414647,"user_tz":420,"elapsed":4,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":["Get ready to look into the embedding vectors of this large pretrained model for the words in the corpus:\n"],"metadata":{"id":"kP9PBa-WTKLO"}},{"cell_type":"markdown","source":["You can create an array that returns the index of each word in the GloVe model's vocabulary:\n"],"metadata":{"id":"aNZd9pwBTL2k"}},{"cell_type":"code","source":["word_to_index = glove_vectors_6B.stoi # Vocabulary index mapping\n","word_to_index['team']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"du8HB1uKSczq","executionInfo":{"status":"ok","timestamp":1753739419705,"user_tz":420,"elapsed":23,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"a89f2a89-b1c9-41b2-baa9-a4899b80a24a"},"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["145"]},"metadata":{},"execution_count":86}]},{"cell_type":"markdown","source":["You will get the embedded vector for a word:\n"],"metadata":{"id":"xmZImxgKTYTE"}},{"cell_type":"code","source":["embeddings_Glove6B.weight[word_to_index['team']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwq3WOtiTTdt","executionInfo":{"status":"ok","timestamp":1753739421096,"user_tz":420,"elapsed":44,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"f8b19d1d-4eb8-46ca-9224-f1364c3fe434"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-2.7011e-02,  1.1299e+00,  4.4708e-02, -4.0380e-01, -4.7284e-02,\n","         9.2736e-02, -2.0715e-01,  2.6137e-01,  2.4730e-01, -8.8769e-01,\n","         3.1309e-01, -1.4940e-01,  4.9929e-03, -1.1520e-01, -1.7990e-01,\n","         6.4681e-01,  1.5044e-01, -3.4580e-01,  2.3370e-03, -7.5788e-01,\n","         1.6048e-01, -2.9066e-02,  1.7194e-01, -4.2799e-02,  3.4297e-02,\n","        -1.1400e-01, -2.1149e-01,  3.6118e-01, -3.3393e-01, -1.3581e-01,\n","         1.7858e-01, -2.3381e-01, -8.3367e-02,  1.0626e-01, -1.7301e+00,\n","         5.2052e-01,  3.7855e-01,  5.5852e-01, -1.0172e-01, -1.8644e-01,\n","        -1.2096e-01, -5.2009e-02,  1.9565e-01, -1.2685e-01, -3.7493e-01,\n","         9.7457e-02,  1.7014e-01,  7.7521e-02, -2.1946e-01,  1.4490e-01,\n","         1.2733e-01, -2.2223e-01, -3.1548e-01,  1.1137e-01, -4.0263e-01,\n","         8.3553e-01, -7.5475e-03,  3.6725e-01,  1.2324e-02, -1.0033e-01,\n","        -6.0014e-01,  4.2763e-01, -2.4048e-01, -2.8162e-01,  4.6409e-02,\n","        -3.7942e-01, -8.0836e-02, -3.2884e-01, -9.3836e-02, -8.6769e-01,\n","        -8.4826e-02,  4.7311e-01, -2.7073e-01,  2.0990e-01, -7.5609e-01,\n","         1.1649e-01,  4.5235e-01, -2.6045e-01,  5.2206e-02,  3.4906e-01,\n","        -5.9366e-02,  3.9424e-01, -6.6567e-02, -1.2907e-01, -2.1789e-01,\n","         5.1554e-02, -1.4604e-01, -5.6169e-02,  3.1792e-01,  1.9815e-01,\n","         1.7534e-01,  9.6423e-01,  4.8888e-01, -5.6890e-01,  2.1305e-01,\n","        -8.8585e-02, -5.3623e-01, -2.9281e-01, -1.1353e-01, -7.2363e-01,\n","         7.0515e-02,  1.0510e-01, -1.7852e-02,  7.1786e-02,  4.1699e-01,\n","        -8.2320e-02,  5.6089e-01,  5.4537e-02,  1.1426e-01,  4.2515e-01,\n","         2.3246e-01, -5.9402e-02, -2.7655e-01, -3.3986e-01,  1.5653e-01,\n","         2.0869e-01, -2.9121e-01, -2.9412e-01, -5.7475e-02, -1.8747e-01,\n","         1.6045e-01,  1.0385e-01,  5.1178e-01,  1.2840e-01, -3.3281e-01,\n","         2.6939e-01, -3.5175e-01,  6.2651e-01,  2.9008e-01,  3.7304e-01,\n","         4.0544e-02, -3.6665e-01, -1.0528e-01, -6.6002e-01, -6.6317e-02,\n","         5.0627e-01,  2.0558e-01, -1.8909e-02, -5.6063e-01, -3.2331e-01,\n","        -3.5732e-01, -1.2919e-01,  1.5296e-01, -7.1057e-02,  9.9959e-02,\n","         6.0830e-02,  4.0220e-01, -1.4335e-01, -4.6526e-01, -7.8211e-02,\n","         5.6127e-01, -4.8189e-01,  5.5877e-02,  6.0063e-02,  7.7121e-01,\n","        -5.2509e-01, -3.7105e-01,  1.6058e-01, -3.5978e-01,  1.8269e-01,\n","        -2.1774e-01, -7.3613e-01, -2.9084e-01, -4.4551e-02,  3.8114e-01,\n","        -1.4108e-01, -1.8333e-01,  3.7169e-01, -1.9730e-01, -2.2467e-01,\n","         3.1620e-01,  8.1412e-02, -8.0367e-01, -2.2259e-01, -2.4526e-01,\n","         4.8726e-01,  1.5435e-01, -3.4813e-02,  2.3038e-01,  5.2597e-01,\n","         5.6235e-02,  2.4087e-01,  9.2098e-02,  2.9834e-02, -1.2290e-01,\n","        -5.6653e-01, -8.5997e-01, -3.8629e-02, -3.5260e-01, -3.0995e-01,\n","         1.4549e-01,  8.1988e-04,  8.5296e-02, -1.5438e-01,  1.9446e-01,\n","         4.5667e-02,  3.7399e-01,  6.2339e-01,  2.4329e-01,  2.7512e-01,\n","         1.7586e+00,  3.4216e-02, -1.6764e-01,  1.3634e-01,  1.0513e-01,\n","        -3.2869e-01,  2.2288e-01,  1.1257e-01, -1.4878e-02, -2.9367e-02,\n","         1.0413e-01,  2.7607e-01, -4.6038e-01,  5.1864e-02,  1.6174e-01,\n","        -2.7844e-01, -9.1567e-02, -4.5173e-02, -8.2913e-02, -3.3233e-01,\n","         1.0870e-01, -3.9585e-01, -3.3200e-01, -1.2790e-01,  5.4628e-01,\n","        -4.0196e-01, -6.4199e-03,  2.4775e-01, -8.4103e-01, -3.4053e-02,\n","         1.2032e-01, -4.1636e-02,  5.1895e-01, -2.6675e-01, -1.8235e-01,\n","        -4.1976e-03, -2.0791e-01,  1.1761e-01,  3.7804e-01,  7.7061e-01,\n","         5.1430e-01,  3.8859e-01,  6.6335e-01,  1.9845e-01, -9.0171e-02,\n","        -7.9311e-02,  1.2066e-01, -2.5846e-02, -4.3176e-02,  1.0805e-01,\n","         4.9527e-01,  3.9891e-03, -1.1265e-01,  1.4894e-01,  5.3257e-01,\n","        -3.1347e-01,  4.0668e-01, -4.0542e-02, -1.6759e-01,  4.2687e-01,\n","        -2.0221e-01, -6.2603e-01,  5.6268e-02,  2.0112e-01,  1.2048e-01,\n","         4.9785e-01, -5.2186e-01, -1.8035e-01, -4.9756e-01, -3.1150e-01,\n","        -3.8850e-01, -2.7542e-01,  5.1444e-02,  1.3145e-02,  6.0204e-01,\n","         9.9091e-02, -1.6328e+00, -3.6475e-01,  3.4421e-01,  6.6319e-01,\n","        -3.5724e-02,  8.3642e-02,  8.0001e-02,  6.8445e-01,  5.5394e-01,\n","         9.9430e-02, -1.3024e-01, -7.7788e-02,  2.3433e-01, -7.2924e-01,\n","        -1.1271e-01, -5.5649e-02, -7.4247e-01,  1.3555e-01,  3.0328e-01,\n","        -1.0663e-01,  1.8475e-01, -8.1355e-01, -5.1386e-02, -3.0962e-01])"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","source":["Let's see how successful the Glove model is in capturing the similarities between words:\n"],"metadata":{"id":"dhDp8m04TiK2"}},{"cell_type":"code","source":["# an array of example words\n","words = [\n","    \"taller\",\n","    \"short\",\n","    \"black\",\n","    \"white\",\n","    \"dress\",\n","    \"pants\",\n","    \"big\",\n","    \"small\",\n","    \"red\",\n","    \"blue\",\n","    \"smile\",\n","    \"frown\",\n","    \"race\",\n","    \"stroll\",\n","    \"tiny\",\n","    \"huge\",\n","    \"soft\",\n","    \"rough\",\n","    \"team\",\n","    \"individual\"\n","]"],"metadata":{"id":"bpDND5YFTd4e","executionInfo":{"status":"ok","timestamp":1753739422484,"user_tz":420,"elapsed":4,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":["Create a dictionary of words and their embeddings\n"],"metadata":{"id":"1CYZa0iqTlxk"}},{"cell_type":"code","source":["embedding_dict_Glove6B = {}\n","\n","for word in words:\n","  # Get the index of the word from the vocabulary to access its embedding\n","  embedding_vector = embeddings_Glove6B.weight[word_to_index[word]]\n","  if embedding_vector is not None:\n","    # Words not found in the embedding index will be skipped.\n","    # add the embedding vector of word to the embedding_dict_Glove6B\n","    embedding_dict_Glove6B[word] = embedding_vector\n","print(embedding_dict_Glove6B)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rj5Hq1kiTjtn","executionInfo":{"status":"ok","timestamp":1753739423781,"user_tz":420,"elapsed":155,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"6008c410-d201-46a6-96a4-8c2e99406362"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["{'taller': tensor([-0.3754,  0.3115, -0.8329, -0.4645, -0.0911,  0.6351,  0.2712,  0.7209,\n","         0.2955, -0.2580, -0.0210,  0.6506,  0.5334,  0.5735, -0.0918, -0.5336,\n","        -0.2819, -0.3535,  0.1951, -0.4246, -0.1618,  0.4481, -0.0129,  0.6492,\n","         0.2425,  0.8531,  0.2076, -0.4344,  0.2263,  0.4841,  0.5112,  0.0511,\n","         0.0074, -0.5669, -0.3787, -0.0809,  0.1811, -0.7922,  0.5570,  0.6542,\n","        -0.1765,  0.0964, -0.0650, -0.5613, -0.3949,  0.4427,  0.3089,  0.2411,\n","         0.3372, -0.1780, -0.1744, -0.2347, -0.0224, -0.4414, -0.4013,  0.4173,\n","        -0.0297, -0.2869,  0.1593, -0.4613, -0.1457, -0.2547, -0.0517, -0.0718,\n","         0.1289,  0.1005,  0.2856,  0.0267,  0.0631, -0.0833,  0.2289,  0.3972,\n","        -0.6216, -0.1166, -0.1255,  0.2723, -0.2424, -0.1635,  0.0404,  0.3058,\n","        -0.2885,  0.5779,  0.1766, -0.1892, -0.3117,  0.1718,  0.3638,  0.2623,\n","         0.2978,  0.2612,  0.5626, -0.4134,  0.6519,  0.7367, -0.9597, -0.5176,\n","        -0.6679, -0.4564,  0.3218, -0.0326, -0.3689, -0.2972, -0.6665, -0.7467,\n","        -0.0318,  0.3655, -0.4206,  0.5094, -0.3450, -0.1659, -0.6468,  0.4758,\n","        -0.2435, -0.5554, -0.2066,  0.1618,  0.1432,  0.5281, -0.4548,  0.5320,\n","        -0.1098, -0.3430,  0.3419,  0.4779, -0.7355,  0.2421,  0.6326,  0.3686,\n","         0.7572, -0.2266, -0.6099,  0.2892, -0.3404,  0.3515,  0.5141,  0.1741,\n","         0.1294, -0.4160, -0.3133, -0.2681, -0.0783, -0.1780, -0.0670,  0.4762,\n","        -0.2587,  0.2485, -0.1334,  0.5659, -0.9426, -0.1202, -0.1976, -0.3684,\n","         0.1929, -0.0503, -0.3554,  0.1018,  0.0707,  0.1347,  0.1358,  0.9477,\n","        -0.2446,  0.4562, -0.1198, -0.2463,  0.0143, -0.3784, -0.8949,  0.0292,\n","         0.4503, -0.5735,  0.0465,  0.2954,  0.2251, -0.3802,  0.8607, -0.3418,\n","        -0.0378,  0.2312,  0.4620, -0.7139,  0.1215, -0.1622,  0.3594,  0.0157,\n","        -0.3082, -0.1772,  0.0697,  0.4953,  0.2355,  0.6828,  0.0313, -0.1281,\n","         0.3897, -0.3460,  0.0937, -0.3319, -0.1838, -0.0885,  0.3456, -0.0097,\n","         0.5237, -0.2170,  0.5106,  0.2065, -0.0370,  0.1672, -0.2834, -0.1002,\n","         0.0477, -0.1895,  0.3749,  0.2181,  0.1493, -0.5674,  0.4302, -0.5120,\n","        -0.2006,  0.1508, -0.1963, -0.7353, -0.0053, -0.3025, -0.1151,  0.3523,\n","         0.2716,  0.5132,  0.5789,  0.5719, -0.3892,  0.2607,  0.4659, -0.1687,\n","        -0.2648,  0.5251, -0.1612, -0.6259, -0.6038,  0.3780, -0.0761, -0.2028,\n","         0.0392, -0.1946,  0.1246, -0.5135, -0.4699, -0.1269, -0.2384,  0.5979,\n","        -0.6615, -0.1177,  0.6290, -0.4771,  0.2772,  0.0508, -0.2944,  0.3521,\n","         0.3000, -0.2384, -0.3984, -0.5530, -0.1161, -0.3055,  0.1819, -0.4885,\n","        -0.2258, -0.6041, -0.0365,  0.2362, -0.2234,  0.2684, -0.3665, -0.1284,\n","         0.2117, -0.5843, -0.4198,  0.3027, -0.6151, -0.2576, -0.9805,  0.5211,\n","         1.0194, -0.1144,  0.2297,  0.1052, -0.1850,  0.0749, -0.2629,  0.4218,\n","         0.3643, -0.0339,  1.1844,  0.2294, -0.0642, -0.4525,  0.5591, -0.6085,\n","        -0.1655, -0.0256,  0.6396,  0.3443]), 'short': tensor([-2.0486e-01, -2.6752e-01, -1.3951e-01,  1.4984e-01,  1.2790e-01,\n","         9.5359e-02, -1.8778e-01,  4.7617e-02,  3.4299e-02, -1.5214e+00,\n","         3.4569e-01,  2.9065e-01, -2.5403e-01,  1.8497e-01,  1.7077e-01,\n","        -1.4983e-01, -4.4048e-02,  3.4835e-01,  1.0122e-01, -2.6475e-01,\n","        -5.7686e-01, -7.5684e-02,  1.9694e-01,  3.4503e-01,  1.3478e-02,\n","         3.8389e-01,  3.8246e-01, -2.6227e-01, -2.1393e-01,  2.3553e-01,\n","        -2.0575e-01,  2.4704e-01,  2.1221e-01,  2.3574e-04, -1.0607e+00,\n","         4.5866e-02, -3.0503e-01,  4.0691e-01,  1.0014e-01,  1.5170e-01,\n","        -5.2935e-01, -1.4733e-02,  6.7743e-02,  1.6784e-01,  1.3116e-01,\n","         3.9026e-01, -1.3503e-01,  7.2359e-03, -3.8533e-01,  3.7626e-01,\n","        -1.4400e-02, -3.9090e-02, -5.4264e-03, -8.3772e-02,  2.1782e-01,\n","         2.4503e-01, -1.8361e-01, -1.6543e-01,  1.8812e-01,  8.1955e-02,\n","         2.1729e-01, -1.9406e-01,  1.1634e-01, -4.7770e-01,  1.1114e-01,\n","        -4.6116e-01,  2.3015e-01,  4.8081e-01,  9.1102e-01,  2.3937e-01,\n","         3.2277e-01,  3.4226e-01,  4.2796e-01, -1.5694e-01,  2.7293e-01,\n","        -2.5440e-01,  1.6534e-02,  4.2598e-01, -1.7941e-01, -5.5739e-01,\n","         1.1630e-01,  3.9690e-01,  4.2544e-01,  1.9902e-01, -5.8551e-02,\n","         7.1922e-01,  5.6925e-01,  3.3625e-01,  3.3579e-01,  2.0141e-01,\n","         6.9895e-01,  4.3463e-01, -2.5472e-01, -1.6776e-01,  3.3418e-01,\n","         1.3674e-01, -4.0682e-01,  6.9711e-02, -8.0003e-02, -3.1487e-03,\n","         1.5313e-01, -1.1387e-01, -4.5928e-01,  1.7785e-01, -5.2118e-01,\n","        -1.2802e-02,  1.2135e-01, -3.2501e-01, -2.5334e-01, -2.0128e-01,\n","        -6.5438e-01,  3.5246e-01,  1.4485e-01, -1.2846e-01,  3.3925e-02,\n","        -1.5336e-01, -1.0684e-01,  1.4291e-01,  2.2102e-01, -6.4926e-01,\n","        -1.4231e-01, -2.0527e-01,  1.7526e-01, -6.9237e-02,  3.0602e-01,\n","         2.9291e-01,  1.8101e-01, -1.2301e-01,  6.6295e-02, -1.4347e-02,\n","         8.2012e-02,  2.3115e-01, -4.5205e-01, -1.2264e-01,  7.2921e-02,\n","        -1.4269e-01, -1.6415e-02, -8.0733e-02,  4.1352e-02, -6.3126e-02,\n","        -1.6079e-01, -1.7858e-01,  1.1484e-02,  1.3463e-02, -2.4011e-01,\n","         1.6895e-01, -2.8665e-02,  1.5278e-01,  3.9823e-01, -2.5177e-01,\n","         4.2923e-01, -1.0860e-01, -4.4764e-01, -6.4016e-02,  4.0038e-01,\n","        -2.9612e-01,  1.6347e-01, -2.0873e-01,  1.6009e-01,  5.4598e-03,\n","        -2.1374e-01, -3.0418e-02,  1.2172e-01, -3.4414e-01, -2.5055e-01,\n","         5.8393e-01, -3.8205e-01,  2.7447e-01, -4.3310e-02,  1.6221e-01,\n","         2.9007e-01, -3.0798e-01, -8.4040e-01,  3.6266e-01, -2.7010e-01,\n","         1.6589e-01,  4.6595e-02,  1.5994e-01, -1.7035e-01, -2.2658e-02,\n","         1.4994e-01, -5.7692e-01,  3.6158e-01, -2.2242e-02,  6.8125e-03,\n","        -4.3459e-02, -1.2790e-01,  3.2468e-02,  4.5527e-02,  1.5103e-01,\n","        -3.9317e-01,  4.5563e-01,  4.2555e-01, -1.7057e-01, -6.0900e-01,\n","        -2.5197e-01, -4.6567e-01, -5.7585e-01,  1.1152e-01,  1.7717e-02,\n","         1.0198e+00,  7.1217e-02, -3.7674e-01,  8.5405e-02,  3.0845e-01,\n","         2.2498e-01, -2.8669e-01,  3.9239e-01, -1.7364e-01, -2.1231e-01,\n","         3.6639e-01, -8.8765e-01,  2.3287e-02,  1.7189e-01,  3.9405e-02,\n","         1.7001e-01, -2.2184e-01, -2.7660e-01, -1.2495e-01, -4.6246e-01,\n","         4.6038e-01, -2.6864e-01, -3.1497e-01,  1.3898e-01,  2.8303e-01,\n","        -2.2051e-01,  2.0501e-01, -3.5446e-01, -1.3358e-01, -8.8106e-02,\n","         2.2006e-01, -1.7055e-01, -3.2246e-01, -1.2691e-01, -5.1829e-02,\n","         1.2345e-01, -1.2272e-01, -9.6900e-02,  2.5584e-01,  2.1391e-01,\n","         6.0032e-01,  1.2052e-01, -1.9365e-02,  4.1449e-02, -1.0799e+00,\n","        -3.4309e-01, -5.2774e-02,  8.3838e-02, -7.4580e-02, -3.2361e-01,\n","        -7.8938e-02, -1.3174e-01, -3.1299e-01, -4.7101e-01,  1.5858e-01,\n","        -4.7424e-01, -2.8966e-01,  5.4269e-01,  8.7734e-02,  9.4758e-02,\n","         1.8094e-01,  1.3027e-01, -4.3173e-01, -1.6383e-01, -3.6945e-01,\n","         1.1496e-01, -7.6631e-02,  6.9105e-03, -3.0614e-02,  3.3856e-01,\n","         1.0578e-01, -2.3723e-01, -4.3040e-01,  5.4816e-01,  6.6698e-02,\n","         6.1397e-02, -1.7978e+00, -1.2563e-02, -7.5064e-02, -2.0785e-01,\n","         7.4856e-02, -3.8814e-01,  1.0366e-01, -2.4791e-01, -2.8506e-01,\n","         7.5147e-02,  2.7682e-03,  3.0914e-01, -5.8325e-01,  9.5371e-02,\n","        -3.4551e-01, -4.3506e-02, -1.5491e-01, -5.3084e-01,  1.1630e-02,\n","         9.3851e-02, -2.4615e-01, -4.2330e-02, -5.2768e-02, -1.7641e-01]), 'black': tensor([-8.6825e-02,  3.6227e-02,  4.6572e-01, -3.7567e-01, -3.8478e-01,\n","        -1.3635e-01,  2.9258e-02,  2.4192e-01, -7.4205e-02, -5.8889e-01,\n","         1.8656e-01,  1.1574e-01,  1.2297e-01,  4.7277e-01,  5.7567e-02,\n","         5.5512e-03,  1.9645e-01,  1.3084e-01, -2.7641e-01, -2.1110e-01,\n","        -2.6682e-01,  1.5479e-01,  4.9475e-01,  1.6682e-01, -3.5990e-01,\n","        -5.2817e-01,  5.0594e-01,  2.2501e-01, -5.4257e-01,  1.7608e-01,\n","         1.0541e-01,  1.5563e-01, -8.8648e-01, -5.7818e-02, -8.7272e-01,\n","         4.3009e-01, -1.2413e-01,  1.5605e-01,  2.0306e-01,  2.8875e-01,\n","         1.0657e-01, -2.6570e-01, -1.3978e-01,  7.3435e-02,  4.0391e-01,\n","        -4.6762e-01, -1.3590e-01, -4.2211e-02, -3.6747e-01, -2.7328e-01,\n","         4.2457e-01, -6.3086e-02,  1.3557e-01, -5.2828e-02, -2.9505e-01,\n","         6.2670e-02, -3.3970e-01, -2.8208e-01,  2.2318e-01, -3.3587e-01,\n","        -3.4670e-01, -3.4361e-01,  5.2057e-01,  1.2140e-03,  2.1841e-02,\n","        -5.8852e-01, -2.6687e-02, -2.1355e-02,  3.9422e-01, -1.3830e-01,\n","         4.5983e-01, -4.4220e-01, -2.8787e-01, -3.3820e-01, -1.9807e-01,\n","        -1.1296e-01,  7.2706e-02,  2.0471e-01,  3.9059e-01, -4.0228e-01,\n","         5.1335e-03, -2.3077e-01,  3.7933e-01, -4.1384e-01,  2.2939e-01,\n","        -2.1594e-01,  5.1277e-01,  1.1294e-01, -1.7049e-01,  9.4362e-02,\n","        -4.7770e-01, -3.8551e-01,  1.6200e-01,  3.4217e-01, -1.3432e-01,\n","         9.0053e-02,  4.1180e-01,  5.1635e-01,  3.8320e-01, -4.9207e-01,\n","         5.0702e-01,  3.2133e-01,  4.5134e-02, -4.8606e-01, -2.2431e-01,\n","         7.2857e-02,  6.1363e-01,  1.1343e-01, -2.3228e-01, -4.4638e-01,\n","         1.6317e-01,  5.3952e-01,  8.2504e-02, -2.9944e-01,  2.1191e-01,\n","         2.4048e-02,  7.2866e-02,  3.2232e-01, -8.1944e-02, -7.1354e-01,\n","        -2.2644e-01, -2.3213e-01,  1.1976e-01, -2.2497e-01, -4.3035e-02,\n","         1.6361e-01,  1.2498e-01,  5.7965e-01,  3.4461e-01, -2.1389e-01,\n","        -4.8776e-01, -3.1363e-01, -3.7673e-02,  8.5819e-02,  2.3679e-02,\n","        -5.4634e-02, -6.4764e-01,  5.3163e-01, -8.9289e-02,  1.2052e-01,\n","         4.1388e-01,  8.0534e-02, -2.1855e-01, -1.0749e-01,  4.1428e-02,\n","         1.0819e-01,  3.8213e-02, -1.4516e-01,  2.5032e-01,  4.3419e-01,\n","         5.2055e-01,  1.3547e-01,  2.7243e-01, -3.6589e-01,  6.1276e-01,\n","         5.2527e-02,  1.5247e-01, -8.8126e-01,  2.9377e-01,  1.6510e-02,\n","        -1.8130e-01, -2.5649e-01,  2.4431e-01,  2.5805e-01, -5.9096e-01,\n","        -4.8691e-01, -5.5553e-01,  6.7436e-01, -1.0320e-01, -5.9864e-01,\n","         7.0564e-01,  4.2308e-02, -6.5878e-01,  3.7361e-01,  2.3997e-01,\n","        -7.5280e-01, -5.4161e-01,  3.2926e-01, -2.1018e-03,  3.1838e-01,\n","         1.1102e-01,  7.1755e-01,  4.8677e-01, -1.9367e-02,  4.9462e-02,\n","        -7.8151e-01,  1.7722e-01,  3.3303e-01, -3.6914e-01,  2.2928e-02,\n","         4.2332e-02,  2.3998e-01,  2.1219e-01,  4.8437e-01,  5.7693e-01,\n","        -4.6900e-03,  1.8041e-01, -3.2227e-01,  2.0047e-02, -5.1123e-01,\n","         1.5963e+00, -3.8556e-01,  6.4036e-02, -4.5507e-01,  1.1343e-01,\n","        -2.6422e-01,  2.8224e-01,  2.7955e-01, -1.4801e-01,  2.7713e-01,\n","         4.3781e-01, -3.5238e-01, -1.4416e-01,  4.3359e-02,  6.5212e-01,\n","         3.5042e-03,  1.3800e+00, -7.9047e-02,  3.1797e-01, -4.6718e-01,\n","         4.3374e-01,  3.0798e-01,  2.5061e-01, -3.2400e-01,  1.9469e-01,\n","        -4.5274e-01, -1.1809e-01, -2.0506e-01, -3.4345e-01, -3.0416e-01,\n","         2.1237e-01, -3.8271e-01, -3.0232e-01,  4.6214e-01, -6.1530e-02,\n","         2.6629e-01,  1.9691e-01, -6.4713e-03, -7.5065e-01, -7.8398e-02,\n","        -2.0391e-01,  3.9792e-01, -1.0820e-01, -4.4070e-02, -7.6149e-01,\n","         1.3622e-01,  4.6195e-01, -5.5866e-01,  2.5120e-01, -1.4804e-01,\n","        -3.1630e-01,  1.1041e-01, -1.7622e-01, -8.5051e-02,  6.7703e-01,\n","        -1.9308e-02, -3.7167e-01,  1.5784e-01,  3.6217e-01, -2.5741e-01,\n","         3.3679e-01,  3.2747e-01,  4.4275e-01, -9.8982e-02, -3.2169e-01,\n","        -2.3243e-01, -7.0403e-02,  1.5559e-01, -7.8529e-01,  8.5591e-01,\n","        -2.6368e-01,  1.1930e-01, -1.5978e-02, -1.6371e-01, -7.8735e-01,\n","         3.3680e-01, -1.7240e+00,  7.4890e-01,  1.5055e-01,  1.4572e-02,\n","        -5.1839e-01,  1.3419e-01,  6.6424e-02, -1.9361e-01, -3.2172e-01,\n","         7.1812e-01, -2.6610e-01,  4.8796e-01,  3.7026e-02, -2.3610e-01,\n","        -7.8550e-02, -6.0675e-01, -5.2821e-01,  8.7722e-01, -7.2705e-01,\n","         2.6274e-01,  2.5088e-01,  6.7862e-02,  2.6733e-02,  2.2466e-01]), 'white': tensor([-2.1079e-01, -7.3710e-02, -2.2369e-01, -5.2861e-01, -4.7914e-01,\n","         1.9868e-01, -2.8629e-01,  2.9288e-01, -1.2305e-01, -8.6209e-01,\n","        -3.0867e-01,  1.4771e-01, -4.0840e-01,  3.3951e-01, -1.4365e-02,\n","         3.2606e-01, -1.8226e-01, -2.2073e-02, -1.5879e-01, -2.2260e-02,\n","        -4.9933e-01, -1.4088e-01,  6.6979e-01,  2.9430e-01, -5.2556e-01,\n","        -5.9957e-01, -2.8106e-01,  9.9069e-02, -5.2881e-01,  8.2451e-02,\n","         9.0757e-02, -3.7652e-01, -9.1248e-01,  4.1685e-02, -1.0276e+00,\n","         7.6928e-01, -1.1164e-01, -2.6860e-01, -1.9233e-01,  1.5796e-01,\n","         3.2466e-01,  6.6595e-01,  7.3415e-02,  2.9291e-01,  4.3042e-02,\n","        -3.8657e-01, -4.0674e-01, -3.2219e-01, -2.2845e-01, -3.3601e-01,\n","        -7.3852e-02,  2.4516e-01,  1.5206e-01,  2.1929e-01, -6.7393e-03,\n","        -2.9413e-01, -5.5468e-01, -1.8828e-01, -4.5911e-02, -7.1682e-02,\n","        -1.2034e-01, -6.0206e-01,  3.2309e-01,  1.9436e-03,  2.4197e-01,\n","        -9.4826e-01,  6.3343e-02, -2.3439e-01, -1.1848e-01, -4.5675e-01,\n","         3.7677e-01, -2.6150e-01, -3.4652e-01, -2.8462e-01, -5.0743e-01,\n","         5.2683e-01,  3.0699e-01,  4.4691e-01, -7.2830e-02, -1.9786e-01,\n","        -1.2219e-01,  1.2706e-01, -8.1021e-02, -1.5009e-01,  2.6762e-01,\n","        -2.8650e-02, -1.0925e-01,  3.8517e-01, -5.7966e-02,  5.3031e-02,\n","        -2.4342e-01, -6.1967e-01, -3.5345e-01,  5.3913e-01, -1.4963e-01,\n","        -2.6235e-01,  1.9887e-01,  3.7270e-01,  3.5875e-01, -4.8336e-01,\n","         2.2394e-01,  1.5793e-01,  2.1723e-01, -6.7626e-02, -2.0675e-01,\n","         9.9727e-04,  3.8619e-01,  1.8668e-01, -1.8480e-01,  2.0553e-04,\n","        -4.3243e-01,  6.3855e-01, -6.6192e-02, -2.6197e-01,  3.1038e-01,\n","         2.6241e-01, -2.0834e-01,  1.6307e-01, -2.5063e-01, -7.2428e-01,\n","        -3.6609e-02, -5.3405e-01, -1.5169e-01, -1.9353e-01, -3.1039e-02,\n","        -5.3715e-02, -1.0271e-01,  6.5711e-01,  4.3131e-01, -2.4322e-01,\n","        -3.6239e-01, -1.2060e-01, -1.8290e-01,  1.7336e-02, -3.1302e-01,\n","         2.1687e-01, -3.3995e-01,  3.2742e-01,  2.2143e-01, -1.9589e-01,\n","         3.9107e-02, -5.8681e-01, -1.2986e-01, -4.2234e-01, -5.0262e-01,\n","         2.0069e-01, -3.6021e-01, -6.8763e-01, -3.5290e-02,  3.2759e-01,\n","         7.1436e-01,  3.4292e-01,  5.2479e-01,  2.0574e-02,  2.9312e-01,\n","        -3.1273e-01, -1.5870e-01, -6.6839e-01,  2.8442e-01, -1.3964e-01,\n","         3.0038e-01, -6.5466e-01,  8.9134e-03,  1.0428e-01, -2.4108e-01,\n","         6.0484e-02, -1.0207e+00,  2.3529e-01,  2.4180e-01, -2.9893e-01,\n","         1.1193e-01, -3.1449e-01, -4.1290e-01,  2.4846e-01, -4.7122e-02,\n","        -9.1323e-01, -2.0908e-01, -3.2284e-01, -4.2072e-02, -2.2779e-03,\n","        -1.3332e-01,  2.7280e-01,  3.7865e-01,  1.1680e-01, -2.5427e-01,\n","        -6.6991e-01,  7.9907e-02, -9.5591e-02,  1.4745e-01,  3.7275e-01,\n","         3.8282e-01,  2.9553e-01,  3.2768e-01, -1.1472e-01,  5.0859e-01,\n","        -1.0515e-01,  4.0712e-01,  8.4256e-02,  7.8885e-02, -7.0087e-01,\n","         1.2432e+00, -3.7519e-01,  9.3555e-02,  5.4552e-02,  7.6045e-02,\n","        -3.3422e-01,  4.7721e-01,  1.8595e-01, -3.3201e-01, -1.4505e-01,\n","         3.8410e-01, -2.6706e-01, -1.6829e-01,  3.0828e-01,  6.1667e-01,\n","         1.1667e-01,  7.3836e-01, -4.8737e-01,  4.8997e-01, -2.0582e-01,\n","         7.7180e-01, -5.9128e-01,  1.5158e-01, -5.1567e-01, -4.9033e-02,\n","        -5.7735e-01,  2.0148e-01,  5.7012e-01, -5.3278e-01, -5.3194e-01,\n","         2.3916e-02, -4.8252e-01,  2.8457e-01,  3.5036e-01, -6.5180e-02,\n","        -1.8881e-01, -1.7370e-01,  1.0849e-01, -2.8246e-01, -1.0427e-01,\n","        -2.6215e-01,  5.3758e-01, -2.5186e-02,  3.9496e-01, -8.4567e-01,\n","        -1.1578e-01,  2.5810e-01, -6.8833e-01,  4.3451e-01, -2.0624e-01,\n","         9.1757e-02,  1.3677e-02,  1.2752e-01, -4.2072e-01,  1.0231e+00,\n","        -5.3708e-01, -1.5932e-01, -1.4374e-01,  2.9048e-01,  1.0142e-01,\n","         2.8181e-01,  3.2445e-01,  3.6288e-01,  1.4106e-01, -3.9196e-01,\n","        -1.9614e-01,  2.3100e-01,  2.8195e-01, -4.2916e-01,  8.7103e-01,\n","        -2.1626e-01, -3.1412e-01, -2.3931e-01, -2.9122e-01, -6.9617e-01,\n","         5.4048e-01, -1.8066e+00,  5.1181e-01,  3.6544e-01, -4.0323e-01,\n","        -3.4493e-02,  2.1008e-01,  4.1616e-01,  3.8804e-02, -7.7406e-02,\n","         5.3483e-01, -1.5566e-02,  6.1116e-01,  2.7065e-01, -3.1139e-01,\n","        -1.3481e-01, -2.4349e-01, -2.9895e-01,  6.8118e-01, -2.9852e-01,\n","        -2.3353e-01,  9.6484e-02, -1.5899e-03, -3.0824e-02,  3.3942e-01]), 'dress': tensor([-6.2674e-01, -1.0394e-01, -3.5119e-01,  2.1756e-01, -2.8120e-01,\n","        -4.1454e-02, -2.0956e-01,  8.2139e-03,  1.4152e-02, -9.8683e-01,\n","         2.9653e-01,  2.3973e-01, -1.6281e-01,  6.9732e-01, -2.8166e-01,\n","        -5.7722e-01,  6.1489e-01,  1.8432e-01, -5.3598e-01, -2.6746e-02,\n","        -9.1363e-02, -1.0655e-05,  3.9050e-01,  2.9741e-01, -6.9476e-01,\n","        -5.6674e-01,  4.6048e-02, -4.4878e-02,  2.7778e-01,  1.1571e-01,\n","         2.8423e-01, -2.4554e-01, -1.2412e-01,  1.2969e-01, -9.1579e-01,\n","         7.5868e-01,  1.0090e-01,  7.5075e-02,  3.7597e-01, -2.8849e-01,\n","        -9.1504e-02, -7.2007e-01, -2.6172e-03, -2.2640e-01, -1.6840e-01,\n","        -2.3273e-01,  1.8469e-01, -2.6558e-01,  7.1328e-02, -9.9455e-02,\n","         5.7710e-02, -1.4206e-01,  3.3873e-01, -5.8049e-01, -4.4895e-01,\n","        -6.5174e-01, -6.9426e-01, -9.7660e-01,  2.8653e-01,  1.4345e-02,\n","         5.2344e-01, -3.9445e-01, -1.2764e-01, -3.5318e-02, -3.6866e-01,\n","        -7.8688e-01,  2.9448e-01, -5.3418e-02,  2.7507e-01,  2.0595e-01,\n","         1.1045e-01, -1.7787e-01, -2.4070e-01, -2.6643e-01,  1.8166e-01,\n","         3.3613e-01,  1.8843e-01,  2.4558e-01, -4.3306e-01, -4.2820e-01,\n","        -2.8667e-01,  2.9037e-01, -3.9065e-01, -2.0201e-01,  7.3041e-01,\n","         1.3969e-01,  1.9305e-01,  2.6546e-02, -7.5088e-02,  2.0489e-01,\n","        -5.3729e-01,  9.5659e-02,  1.5826e-01,  2.2857e-01, -3.7340e-03,\n","        -6.1572e-02,  3.1135e-01,  6.0075e-02,  2.5046e-01,  1.0783e-01,\n","         6.9073e-01,  5.6754e-01, -2.2793e-01, -1.1157e-01, -3.6071e-01,\n","         1.8694e-01,  4.7157e-01,  3.1270e-01, -5.7754e-03,  4.0416e-02,\n","         1.7807e-01,  7.3345e-01, -5.9468e-02,  3.9800e-01, -1.1010e-01,\n","         2.0406e-01,  1.1429e-01,  4.1487e-01,  1.5558e-01, -9.1342e-01,\n","         1.5613e-01,  3.3057e-01,  8.2833e-01,  1.6657e-01, -1.1297e-02,\n","        -1.4060e-01,  2.7715e-02,  1.7255e-01,  1.0299e-01, -3.7639e-02,\n","         1.5663e-01, -3.9614e-01, -1.4953e-01, -6.8150e-03,  2.6054e-02,\n","         3.0380e-01, -3.4322e-01, -2.3277e-01, -1.7795e-01,  2.6048e-01,\n","         5.5770e-02,  1.6868e-01, -2.4158e-02, -4.2382e-01, -9.5212e-02,\n","        -4.4879e-02, -1.9380e-01, -9.9206e-02,  4.1231e-01,  3.9928e-01,\n","         1.0378e-02,  1.2136e-01,  3.6942e-01, -7.1826e-01,  2.7203e-01,\n","        -1.6864e-01, -2.2169e-01, -3.1295e-01,  5.5455e-01,  2.4566e-01,\n","         9.3537e-02, -2.4791e-01, -3.0417e-01, -1.0839e-01, -2.0591e-01,\n","        -1.4260e-01, -4.8406e-01,  4.8612e-01,  2.8556e-01,  1.3601e-01,\n","        -4.9919e-01,  1.5521e-02, -9.8815e-02,  3.0341e-02,  1.3729e-01,\n","        -3.5768e-01,  6.1841e-02,  6.8095e-01, -2.5306e-01,  7.3388e-02,\n","        -4.1408e-02,  1.9299e-02,  1.9628e-01, -2.6353e-01,  3.1297e-01,\n","         3.5845e-01,  4.2479e-01,  3.4665e-01,  7.8535e-02, -4.3310e-01,\n","         1.6497e-01, -1.8932e-01, -3.7463e-01,  1.6856e-01,  9.5496e-02,\n","         1.8139e-01, -7.9567e-01, -2.7234e-01, -3.1023e-01, -9.0079e-01,\n","         9.7775e-01,  3.9661e-02,  7.1410e-01,  7.1496e-01,  1.0651e+00,\n","        -5.0777e-02,  4.9358e-01,  5.1251e-01, -5.7751e-01, -1.6322e-01,\n","        -7.4272e-02, -1.8130e-01,  2.3794e-02,  6.0541e-01,  4.9659e-02,\n","        -3.1790e-01,  1.1442e+00, -9.2310e-01, -5.4919e-02, -2.8874e-01,\n","         2.5827e-01,  1.3271e-01,  3.3707e-01,  5.4579e-01, -6.8313e-02,\n","        -1.5490e-01,  1.5591e-01, -8.2880e-03,  3.4560e-01,  4.3123e-02,\n","         5.4711e-01,  8.9527e-02, -4.7170e-01,  2.2176e-01,  5.6354e-01,\n","         9.3359e-02,  1.9982e-01, -3.3911e-01, -1.0226e-01,  4.6815e-01,\n","         4.0148e-01, -1.0855e-01, -2.7517e-01,  8.0044e-01, -1.6396e-01,\n","         8.6628e-01, -5.3153e-01, -4.9585e-01,  4.9227e-01, -1.3488e-01,\n","         2.4167e-01,  3.4727e-01, -8.2801e-02, -2.1270e-01,  3.5837e-01,\n","        -6.3224e-01,  1.0822e-01,  5.2492e-01,  1.1530e-01, -3.7781e-01,\n","        -1.6894e-01, -4.5417e-02,  4.6968e-01, -3.0187e-01, -8.2696e-01,\n","        -5.1131e-01, -1.6794e-01,  2.4929e-01, -1.7730e-01, -7.2442e-02,\n","         3.4033e-02, -3.3523e-01,  2.8609e-01,  4.3064e-02, -4.7368e-01,\n","        -2.4811e-02, -1.2771e+00,  7.2154e-02, -5.4013e-01, -2.5883e-01,\n","         4.0890e-01,  1.4222e-01,  3.0463e-01, -2.1010e-01, -2.4110e-01,\n","         4.2290e-01, -3.1118e-01,  6.1183e-01, -2.2644e-01, -2.7363e-01,\n","         3.5295e-01, -3.3466e-01, -5.6336e-01,  1.1848e+00, -1.0471e-01,\n","        -5.8642e-01,  4.4058e-01,  3.9987e-01,  9.9890e-01, -9.6597e-02]), 'pants': tensor([-3.3992e-01, -3.6266e-01, -1.9109e-01,  3.0656e-01, -6.1212e-02,\n","        -3.5827e-02, -4.8484e-01, -3.3825e-01, -1.0025e-01, -6.6898e-01,\n","        -1.4936e-01,  2.8746e-02, -1.8091e-01,  4.7946e-01, -3.9702e-01,\n","         5.2248e-01,  1.3355e-01, -1.5999e-01, -2.4395e-01, -8.5987e-02,\n","        -5.0652e-02,  3.8335e-01,  3.3787e-01, -4.6552e-01, -7.3731e-01,\n","        -4.3354e-01,  8.4840e-01, -7.3403e-01,  2.1084e-01,  3.6687e-01,\n","         1.9218e-02, -2.7527e-01, -3.3433e-02, -1.6163e-01, -6.1806e-01,\n","         7.0475e-01, -3.5066e-01,  4.4062e-02,  3.0660e-01,  5.6419e-01,\n","        -4.4662e-01, -7.3455e-01, -4.2809e-01, -4.8374e-01,  3.2728e-01,\n","         2.9018e-01,  7.3621e-01, -4.9987e-01, -4.5009e-01,  1.5166e-01,\n","        -7.5034e-02, -3.9074e-01,  1.6374e-01, -3.1725e-01, -2.0202e-01,\n","         1.1555e-01, -4.2389e-01, -8.1432e-01,  8.5691e-02,  1.9510e-01,\n","         8.5349e-02, -3.4313e-01, -3.1143e-01,  1.3564e-01, -1.7638e-01,\n","        -3.7568e-01, -2.0040e-01,  1.5224e-01, -1.6860e-01,  3.4341e-02,\n","         5.7230e-01, -1.2561e-01,  1.3083e-01, -4.7278e-02,  3.4377e-01,\n","         4.5947e-02, -6.5432e-02,  2.5031e-01, -1.2310e-01, -8.8720e-01,\n","        -1.9074e-01,  4.5544e-01, -4.7362e-01, -9.6186e-02, -1.9938e-01,\n","         4.0041e-01,  5.5112e-01,  1.7461e-01, -2.8455e-01,  1.2566e-01,\n","        -1.4077e-01,  2.5453e-01, -2.2786e-02,  8.2605e-02,  9.2405e-02,\n","         2.0454e-01,  1.2995e-01,  6.5997e-01,  3.7773e-01,  8.1699e-02,\n","         3.0161e-01,  9.3953e-01, -1.4209e-01,  4.4015e-01, -8.1341e-01,\n","        -3.9443e-02,  3.0457e-01,  1.2946e-01, -1.3172e-01, -2.5829e-01,\n","        -5.7327e-01,  2.7894e-01, -8.6084e-02,  1.1264e-02, -5.4200e-02,\n","         3.5411e-01, -9.2796e-03,  2.7060e-01,  3.2018e-01, -6.8685e-01,\n","        -4.1099e-02, -1.1074e-01,  1.2164e+00,  1.6768e-01, -5.5897e-02,\n","         4.7750e-02,  2.7611e-01,  1.4295e-01,  4.0832e-01,  1.5842e-01,\n","        -4.7035e-02, -2.9855e-01, -6.0351e-01,  1.9469e-01, -1.6870e-01,\n","         6.2268e-02, -4.7693e-01,  9.6985e-02, -3.4536e-03,  3.3074e-02,\n","        -2.3719e-01, -4.0691e-01,  1.5337e-01, -4.6098e-01, -1.6798e-01,\n","         2.8677e-01, -7.1324e-01,  9.7411e-02,  1.1692e+00,  8.7560e-02,\n","         4.6327e-04,  1.9586e-01,  1.4538e-01, -7.3116e-01,  2.4200e-01,\n","        -4.6261e-01,  2.2924e-01,  1.3167e-02,  4.7556e-01,  3.6870e-01,\n","         2.4817e-01, -7.7264e-01, -5.2829e-01, -2.6262e-02,  2.4883e-01,\n","        -6.9650e-01,  1.5282e-02,  1.3007e+00,  2.6073e-01,  6.7301e-02,\n","         8.5578e-02,  2.6658e-01, -5.3073e-01,  6.0764e-01, -9.5752e-02,\n","        -1.8985e-01,  1.1133e-01,  4.7073e-01,  1.1318e-01, -2.3123e-01,\n","         1.9316e-01,  1.4947e-01,  2.2079e-01,  1.5404e-01,  4.7264e-01,\n","        -3.9430e-01,  1.0070e+00,  5.2795e-01,  4.0736e-01, -2.1795e-02,\n","         6.0879e-01,  1.3681e-01, -5.1644e-02,  4.0973e-01, -3.0789e-01,\n","        -2.8177e-02, -7.7594e-01, -2.7638e-01, -3.8086e-01, -3.8290e-02,\n","         7.5577e-01,  1.6303e-01,  9.8601e-01,  4.6905e-01,  5.3942e-01,\n","         1.4198e-01,  3.5370e-01,  4.6872e-01, -6.8522e-01, -4.3673e-01,\n","        -2.6537e-01, -7.1234e-01, -3.6240e-01,  9.2582e-01,  8.6266e-01,\n","        -7.7569e-02,  3.9526e-01, -6.5561e-01,  3.0151e-01, -9.0248e-01,\n","         5.2850e-01,  8.9496e-02,  3.4865e-01,  4.1031e-01,  1.9545e-01,\n","        -3.0636e-01,  2.0970e-02, -2.6787e-01, -5.6129e-01, -4.5033e-01,\n","         6.9093e-01, -6.9118e-02, -2.6985e-01,  1.1290e-01,  7.7207e-01,\n","        -3.7411e-01,  2.7517e-01, -1.1639e-01, -5.8403e-01,  6.3941e-01,\n","         5.9906e-01, -9.3311e-02, -5.7236e-01,  5.7401e-01, -1.6082e-01,\n","         3.6643e-01, -4.3293e-01, -5.4920e-01,  3.4790e-01, -2.7954e-01,\n","        -5.5937e-01, -1.6350e-01,  1.4200e-01, -4.0423e-01,  4.2370e-01,\n","         6.7246e-02, -1.8896e-01,  6.0463e-01, -3.5466e-01, -4.3022e-01,\n","         3.6116e-01, -6.0129e-01,  8.1385e-02, -3.1081e-02, -3.6348e-01,\n","        -8.7775e-02, -5.6356e-01,  2.4898e-01, -9.3008e-01,  2.9505e-01,\n","         2.4758e-02, -1.8134e-01, -1.8905e-01, -2.9822e-02, -4.5365e-01,\n","        -4.0079e-01, -4.9012e-01, -8.0159e-02, -7.7909e-01,  3.8660e-01,\n","         4.0720e-01,  1.4037e-01,  5.5660e-01,  2.6117e-01, -5.2446e-01,\n","         3.7852e-01, -5.2926e-01,  2.4801e-01, -4.3450e-01, -4.8518e-01,\n","        -1.9417e-01,  3.9405e-01, -6.7549e-02,  9.4022e-01, -4.5885e-01,\n","        -3.6031e-01,  2.2882e-01,  3.2258e-01,  6.1020e-01, -1.5682e-01]), 'big': tensor([ 5.3202e-02,  3.2654e-01, -1.1270e-02, -8.2123e-02,  7.1037e-02,\n","         4.4781e-01,  4.4859e-02,  4.1380e-01, -2.7196e-01, -8.9759e-01,\n","        -1.3761e-01,  1.3004e-01, -7.5357e-02,  3.8629e-01,  1.7758e-01,\n","        -2.9943e-01, -1.9235e-01, -3.0964e-01,  3.2962e-01,  8.6086e-02,\n","         5.2474e-01,  6.3456e-01,  4.8114e-01,  4.1667e-01, -2.6752e-01,\n","         2.8658e-01, -2.6327e-02, -5.4687e-01,  1.9495e-01, -1.7815e-01,\n","        -3.9229e-01, -9.0400e-02, -3.4012e-01,  2.2120e-01, -1.6101e+00,\n","         3.8802e-01, -2.4336e-01, -1.7560e-01, -2.0712e-01,  2.0394e-01,\n","        -2.5578e-02, -4.5187e-01,  3.3415e-01,  2.7383e-01, -3.9909e-01,\n","         1.6407e-01,  4.6706e-01, -4.4217e-01, -8.4489e-02,  2.5391e-01,\n","         5.9938e-01,  1.1946e-01, -1.0521e-01, -1.4147e-01, -4.5396e-01,\n","         2.6155e-01, -5.6754e-01,  1.5196e-01,  3.1752e-01, -2.1125e-02,\n","         3.0054e-01, -8.8797e-02, -9.2661e-02,  1.2387e-01,  2.3050e-01,\n","        -1.2303e-02, -5.9526e-02,  1.0790e-01, -6.8127e-02, -2.9459e-02,\n","        -7.7968e-03,  4.1705e-01, -1.0040e-01,  1.2982e-01, -1.3223e-02,\n","        -1.1526e-01, -6.5731e-02,  5.4774e-02,  2.0605e-02, -5.2391e-01,\n","        -8.9419e-02,  5.1287e-02,  2.1643e-01, -3.1757e-01,  6.2864e-01,\n","         3.0463e-01,  1.1931e-02,  3.0312e-01, -4.8976e-02, -5.6590e-01,\n","         2.3477e-01,  2.8488e-01, -2.4284e-01, -1.1837e-01, -2.2553e-01,\n","        -1.4001e-01, -1.9238e-01, -2.2480e-01, -6.1711e-02, -2.3125e-01,\n","        -7.9984e-02,  1.2241e-01, -3.6515e-01, -2.2947e-01,  7.8941e-03,\n","         1.4803e-01, -1.2649e-01,  2.8246e-02, -4.1702e-01, -1.1158e-01,\n","        -4.9910e-01, -5.6353e-01, -4.6138e-01, -1.8227e-02,  5.5521e-01,\n","         7.8952e-02,  1.4393e-01,  3.7751e-01,  4.6950e-02, -5.3430e-01,\n","         1.1517e-01, -2.7230e-01,  2.2937e-01,  1.7617e-01,  3.1728e-01,\n","        -7.8928e-02, -5.5615e-03,  1.4917e-01, -1.7789e-01, -3.0649e-01,\n","         2.9659e-01,  4.7704e-01, -5.5835e-01,  3.5082e-02,  1.7096e-01,\n","        -2.5288e-01,  5.1560e-02, -5.6329e-02,  4.2230e-02,  3.8741e-02,\n","        -8.0193e-02,  1.3952e-01,  7.0648e-01,  1.1988e-01, -3.2750e-01,\n","        -8.7163e-03,  1.0524e-01,  3.1645e-01, -7.1287e-02,  2.2948e-01,\n","         1.5596e-01,  3.6893e-01, -2.1014e-01, -2.9139e-02,  4.6407e-01,\n","        -7.8003e-02,  1.2458e-01, -6.9225e-02, -5.8424e-01, -7.8226e-02,\n","         8.2829e-02,  1.8654e-01,  1.7078e-01,  1.6484e-01, -1.2538e-01,\n","         1.4431e-02,  4.4243e-02,  2.4854e-01, -1.2925e-02,  4.2898e-03,\n","         8.3215e-02, -2.0077e-01, -7.2477e-01, -2.0139e-01,  4.1344e-02,\n","        -9.7364e-02, -8.1314e-02,  5.6293e-02,  3.7262e-01,  4.2560e-01,\n","         4.5101e-01,  7.4838e-02,  4.6719e-01,  1.3900e-01, -1.8487e-01,\n","        -2.2201e-01, -6.4360e-02,  9.1974e-02,  1.1689e-01, -2.3366e-01,\n","         1.2914e-01,  1.2386e-01, -1.2900e-01, -4.4109e-02,  3.9721e-01,\n","        -6.1978e-02,  3.8883e-02,  1.1275e-01,  3.7979e-01,  1.3575e-01,\n","         1.8973e+00, -2.9059e-01,  7.2478e-02, -2.2316e-01, -4.2648e-01,\n","        -1.2234e-01, -3.0966e-01,  4.0260e-01,  1.8576e-02, -4.4676e-01,\n","        -6.4271e-01,  1.6120e-01, -9.6531e-02, -6.6292e-02,  2.8503e-01,\n","         2.8944e-01,  2.0129e-01,  3.8182e-01,  8.6765e-02, -3.2541e-01,\n","         2.2295e-01,  5.7072e-02,  2.4878e-01, -1.6025e-02,  1.4448e-01,\n","        -5.5270e-02, -1.0185e-01,  1.3745e-01,  1.5056e-02, -5.0501e-02,\n","         7.8285e-02, -1.0455e-01, -3.2698e-01, -2.1523e-01,  6.9816e-02,\n","         1.0553e-01,  1.5315e-01,  1.3057e-03, -2.6675e-02, -1.8643e-01,\n","         2.5311e-01,  2.0835e-01,  5.0941e-02, -7.6221e-02, -1.1740e+00,\n","        -5.3818e-01, -2.0022e-01,  1.8137e-01,  2.8364e-02, -3.2037e-01,\n","        -1.0306e-02, -1.3441e-01, -1.5794e-01,  5.2013e-02,  1.3071e-01,\n","        -1.8834e-01, -3.4213e-01, -1.5006e-01, -3.6625e-01,  5.1873e-02,\n","         2.6475e-01, -3.3269e-01,  5.3389e-01,  3.7694e-01,  2.9248e-01,\n","        -2.6069e-01, -2.9506e-01, -2.7485e-01,  2.6808e-01,  5.4107e-01,\n","         2.0729e-01, -2.5498e-01, -2.3753e-01, -6.9640e-02,  1.2649e-01,\n","        -5.2191e-02, -1.9453e+00,  1.9465e-01, -3.0956e-01,  1.4595e-01,\n","        -5.5976e-01,  5.8851e-01,  2.9796e-03,  5.3247e-01, -1.1014e-01,\n","         1.0197e-01, -1.9553e-01, -5.1859e-02,  3.7775e-01, -2.0514e-01,\n","         6.7855e-02,  1.0475e-01, -4.8275e-02,  1.5864e-01, -4.2757e-03,\n","         1.8459e-01,  9.6166e-03, -3.9005e-01, -1.4410e-01,  4.2055e-01]), 'small': tensor([-4.3299e-01,  3.2830e-01, -9.4275e-02, -7.4577e-01,  9.7294e-02,\n","         3.0343e-01,  2.4456e-01,  2.3424e-01,  1.1644e-01, -1.3854e+00,\n","        -2.0632e-01,  3.3973e-01, -5.3957e-02,  3.1498e-01,  1.1494e-01,\n","         2.9251e-01, -2.6184e-01, -3.1321e-02,  5.1073e-02, -3.5136e-01,\n","        -6.8788e-02,  2.7995e-01,  6.6134e-01,  4.9038e-01, -4.6781e-01,\n","        -9.0045e-02, -2.0377e-01, -3.2092e-02, -2.8013e-01,  3.4487e-01,\n","        -1.5877e-01,  4.6025e-01, -3.5421e-01,  4.9010e-01, -3.0408e-01,\n","         4.9700e-01, -9.7760e-02,  1.8096e-01, -7.8735e-02,  4.3619e-02,\n","        -3.5727e-02, -5.5472e-02,  5.2865e-01,  3.6847e-01,  5.8002e-02,\n","        -3.2853e-02,  4.4681e-01,  1.0571e-01,  2.3000e-01,  5.4184e-01,\n","         4.0109e-01,  2.7132e-01,  2.6067e-01,  1.6484e-01, -1.9650e-01,\n","        -6.7482e-02, -6.9092e-01,  5.2957e-02,  7.1007e-01,  1.3010e-02,\n","         3.1779e-01, -3.5350e-01,  4.7409e-01,  6.0420e-02,  2.9609e-01,\n","        -8.0971e-02, -4.0223e-02,  3.1086e-01, -5.9048e-02,  8.9527e-02,\n","        -2.3671e-02, -3.1117e-03,  4.8292e-01,  2.5221e-01, -4.9055e-01,\n","         1.5609e-02, -2.1219e-01, -2.6254e-01,  1.0606e-01, -5.4849e-01,\n","        -7.9454e-02,  3.8384e-01, -1.3757e-01,  2.2812e-01,  4.9773e-01,\n","         2.4303e-01,  2.5780e-01, -1.0301e-01, -4.7559e-01, -1.2228e-01,\n","         5.8216e-01,  2.8679e-01, -2.4309e-01, -4.8456e-02,  2.8120e-01,\n","        -2.3229e-01,  3.1413e-01,  9.6975e-02, -2.1616e-01,  1.1934e-01,\n","         1.4158e-01,  1.2211e-01, -2.4723e-01, -5.6947e-01, -6.5794e-01,\n","         8.9153e-02,  2.1462e-01, -3.4932e-01,  1.7141e-01,  9.1154e-02,\n","        -5.5764e-01, -1.0458e-01,  1.0656e-02, -9.6524e-02,  8.5704e-02,\n","         6.4610e-02, -6.8728e-02,  1.8041e-01,  1.5595e-01,  1.2814e-01,\n","         1.6452e-02,  1.6550e-03,  4.1456e-01, -2.1214e-02,  7.3860e-02,\n","         2.1316e-01,  2.9834e-02,  2.4059e-01, -5.1654e-02, -1.0135e-01,\n","         3.4422e-02, -1.9056e-01, -2.1823e-02,  1.3194e-01,  4.8944e-01,\n","        -5.0350e-02,  3.1114e-01, -7.2967e-02, -8.2687e-02, -3.5334e-01,\n","        -1.3308e-02,  2.4941e-01, -1.3372e-01,  1.6167e-01, -5.1950e-01,\n","        -8.7009e-02,  2.1790e-01,  2.5386e-01, -7.3476e-02,  1.6088e-01,\n","        -5.9382e-02, -5.0249e-01, -1.5807e-01, -1.6757e-01,  4.4968e-01,\n","         2.2458e-01,  1.9195e-01,  3.3002e-01, -3.3566e-02, -2.2207e-01,\n","         1.5534e-01,  6.9113e-02,  2.6469e-01, -5.1834e-03, -2.0115e-01,\n","        -2.2659e-01, -1.2001e-01, -7.4060e-02,  5.5871e-02, -4.3792e-02,\n","        -6.6209e-02, -4.7115e-01, -2.7074e-01,  1.7173e-01, -2.5237e-01,\n","        -2.6578e-01, -2.8926e-01, -6.2596e-03,  4.9771e-01,  4.8775e-02,\n","         3.2303e-01, -1.2185e-01,  2.1246e-01, -6.8896e-02,  3.7686e-01,\n","        -4.9708e-01,  1.5416e-01,  1.7898e-01,  1.8014e-01, -1.0665e-01,\n","         4.2314e-01,  4.8977e-01,  1.2411e-01,  1.7776e-01,  1.9731e-01,\n","         5.0339e-01,  2.1515e-02, -1.9975e-01, -1.9695e-01, -2.8275e-01,\n","         6.9624e-01,  1.6805e-02, -2.8103e-01,  2.2848e-01,  1.2902e-01,\n","        -2.9393e-01, -3.8387e-01,  7.1186e-02, -4.8307e-02, -9.0567e-02,\n","         2.8124e-01,  7.7570e-02, -6.6275e-02, -2.0985e-01,  1.2430e-01,\n","         8.6875e-02,  4.4581e-01, -2.2417e-02, -4.2191e-01,  1.9197e-01,\n","         4.5082e-01,  1.1105e-01, -4.9147e-01, -9.0860e-02,  1.3810e-01,\n","         2.3229e-03,  2.1261e-02, -2.2926e-01,  7.1240e-02, -9.5339e-02,\n","         8.2059e-02, -5.0062e-01, -3.0259e-01,  6.1177e-02,  4.5983e-01,\n","         4.7468e-01,  9.1748e-02,  2.2264e-01, -3.7203e-01,  1.0786e-01,\n","         3.5490e-01,  2.1040e-01,  1.9999e-01,  7.6104e-02, -1.3045e+00,\n","        -5.7747e-01,  5.1900e-01,  6.8469e-02, -3.8347e-01, -1.2574e-01,\n","         4.7811e-02, -2.1214e-01, -2.4007e-01, -2.6386e-01,  5.0679e-01,\n","         6.4160e-01, -1.7551e-01, -2.0360e-01, -2.2474e-01,  2.2709e-01,\n","         2.0689e-01,  8.1320e-02,  2.8826e-01,  1.5282e-01,  1.9622e-01,\n","        -3.5670e-01, -2.5604e-01,  2.1318e-01, -1.4043e-01,  5.1106e-01,\n","        -1.3195e-01,  1.7747e-01, -1.2300e-01,  1.9980e-01, -2.0783e-01,\n","         3.4355e-01, -2.4089e+00,  3.4228e-01, -3.9874e-01,  2.8494e-01,\n","        -5.4060e-01,  5.4631e-01, -1.4950e-01,  1.6375e-02, -3.0254e-01,\n","         2.9325e-01, -7.2363e-02,  1.9331e-01,  4.4071e-01,  3.1411e-01,\n","        -6.3125e-02, -2.8707e-01, -1.6933e-01, -1.5032e-01, -3.0977e-01,\n","         8.1411e-01, -2.5677e-01, -1.9407e-01, -1.1114e-01, -5.8074e-02]), 'red': tensor([ 0.0597, -0.1347,  0.2676, -0.4744,  0.0157, -0.2438, -0.4769,  0.3430,\n","         0.1376, -0.9344,  0.5571, -0.1929, -0.2644,  0.6935,  0.6265,  0.2321,\n","        -0.4677, -0.1534, -0.5211, -0.2346, -0.4502, -0.2995,  0.1070, -0.0301,\n","        -0.0246, -0.5638,  0.0821,  0.2978, -0.3952,  0.2328, -0.0757, -0.1718,\n","        -0.6831, -0.1567, -0.6763,  0.3781,  0.1814, -0.4425, -0.2153,  0.0112,\n","         0.1430,  0.0668,  0.0681,  0.4543, -0.2107, -0.2279, -0.3376,  0.3255,\n","        -0.8724, -0.5283, -0.5589,  0.1323, -0.0974, -0.2124, -0.4262, -0.3460,\n","        -0.3417,  0.0239,  0.2745, -0.2793, -0.2557, -0.4343,  0.0472, -0.1108,\n","        -0.0223, -0.6263, -0.4556,  0.1209, -0.0338, -0.1995,  0.5427,  0.4965,\n","        -0.4060,  0.2406, -0.0561, -0.1025,  0.8538, -0.2757,  0.2765, -0.3030,\n","        -0.2426,  0.0460,  0.0072, -0.2966,  0.2217, -0.2431, -0.0724,  0.1518,\n","         0.1742,  0.2314,  0.3629,  0.6601, -0.0064,  0.1006,  0.1404,  0.6342,\n","         0.4430, -0.1534,  0.0916, -0.1321,  0.7852,  0.0440,  0.3049, -0.0185,\n","        -0.4145, -0.1579,  0.1641,  0.5376, -0.4105,  0.0667, -0.3178,  0.4566,\n","        -0.0140, -0.0709,  0.3242, -0.4596, -0.6136,  0.9193,  0.2426, -0.6579,\n","        -0.2552, -0.5654,  0.3014,  0.4911,  0.1020, -0.2596, -0.1487,  0.4642,\n","         0.2248, -0.4764, -0.0299,  0.2890, -0.4783, -0.1265,  0.1075,  0.0449,\n","        -0.2678,  0.0441, -0.1664,  0.2029,  0.0022,  0.4516, -0.5185, -0.6142,\n","         0.5438,  0.3434, -0.3248, -0.5089, -0.2577, -0.0466,  0.7549,  0.2686,\n","        -0.2056,  0.0382,  0.6745, -0.1108,  0.4748, -0.6802, -0.2731,  0.1462,\n","         0.1043, -0.3458,  0.2770, -0.1382, -0.0538,  0.2687, -0.4791,  0.3746,\n","        -0.2580, -0.1784, -0.3939,  0.1192, -0.1136,  0.0329, -0.1021, -0.6825,\n","         0.4078, -0.0077,  0.1076, -0.0660,  0.1124,  0.4557,  0.2322,  0.0133,\n","        -0.4448, -0.6042,  0.1970,  0.0452,  0.1787, -0.0637,  0.3369,  0.5788,\n","         0.0574, -0.0790,  0.8948,  0.1562, -0.0309,  0.1613, -0.1238,  0.1798,\n","         1.6150,  0.0479,  0.5624,  0.2352,  0.0298, -0.1559,  0.4653,  0.0040,\n","        -0.0039,  0.0081,  0.1154, -0.0392, -0.5123, -0.4431,  0.4191,  0.0908,\n","         1.3399, -0.0831,  0.0976, -0.2675,  0.6350, -0.7596, -0.2061, -0.0751,\n","         0.0398, -0.6995, -0.0576, -0.0583, -0.4159, -0.9574, -0.2506,  0.0298,\n","         0.0496,  0.1752,  0.1953,  0.1629, -0.1533,  0.0677, -0.0207, -0.1242,\n","        -0.4193,  0.1723, -0.2463, -0.0314, -0.2572,  0.1901,  0.7296, -0.1464,\n","        -0.0480, -0.4316,  0.2095,  0.2342, -0.4389, -0.2986,  0.8016, -0.1127,\n","        -0.4084, -0.1521, -0.0941, -0.2704, -0.0529, -0.3334,  0.6172, -0.0951,\n","        -0.5901, -0.3340, -0.1757,  0.0506, -0.1908, -0.1804,  0.0591, -0.4714,\n","         0.1029, -0.2107,  0.0840,  0.7376, -1.9625, -0.0279, -0.2315, -0.0887,\n","         0.1062,  0.5975,  0.2517, -0.0102,  0.1654,  0.4540,  0.2728,  0.1619,\n","         0.3752, -0.1459,  0.0327,  0.2136, -0.8280,  0.8884, -0.7362,  0.3418,\n","         0.2736, -0.0898,  1.0002, -0.1592]), 'blue': tensor([ 1.3590e-02,  7.5997e-04,  2.4608e-01, -2.5226e-01, -2.6381e-01,\n","        -1.8235e-01, -2.8545e-01,  1.6141e-01, -5.8719e-03, -8.8741e-01,\n","         3.2506e-01,  1.2595e-02, -5.2006e-01,  6.6408e-01,  2.6794e-01,\n","         9.1895e-02, -2.4301e-01, -8.1345e-02, -1.8211e-01,  6.6095e-02,\n","        -4.6120e-01, -1.7391e-01,  2.9813e-01,  4.1042e-01,  2.3668e-01,\n","        -8.5411e-01, -2.2062e-01,  1.2718e-01, -4.5106e-02, -1.6213e-02,\n","         2.7401e-01, -3.2875e-01, -5.5721e-01,  1.0901e-01, -8.2414e-01,\n","         9.6693e-01, -2.2464e-01, -2.3614e-01, -1.5979e-01,  2.9582e-03,\n","         6.5369e-03,  3.3008e-01,  2.8742e-01,  5.5051e-01, -2.2691e-01,\n","        -6.4095e-02, -2.3025e-01, -1.7280e-01, -2.5803e-01, -9.8065e-01,\n","        -1.1780e-01,  9.5393e-02,  2.1137e-01, -1.8096e-01, -3.6605e-01,\n","        -7.8029e-02, -1.2665e-01,  5.7800e-02,  7.1365e-01, -1.9216e-01,\n","         3.2366e-02, -2.8513e-01,  2.1081e-02, -3.3045e-02,  6.7519e-01,\n","        -8.4417e-01, -2.4907e-01, -8.8714e-02,  2.3046e-01,  1.4198e-01,\n","         1.3416e-01,  2.5668e-01, -7.9085e-02,  1.9842e-01, -1.3846e-01,\n","         3.6391e-01, -9.1628e-02,  1.1706e-01,  1.4300e-01, -7.2168e-01,\n","        -7.3082e-02,  4.5257e-02, -6.3108e-01, -6.6615e-02,  4.0850e-01,\n","         2.6346e-01,  3.6138e-01,  2.1058e-01, -3.5040e-01, -5.0723e-01,\n","         5.4811e-01,  3.0481e-01,  2.0085e-01,  2.3366e-02, -4.6658e-01,\n","         6.7701e-01,  3.8631e-01,  8.4022e-02,  1.0921e-01, -2.4064e-01,\n","         6.4600e-01,  3.6534e-01,  1.1379e-01,  2.7383e-01, -4.6748e-01,\n","        -2.0031e-01,  4.0767e-01,  1.9806e-01, -4.5753e-01,  4.0717e-02,\n","        -3.8852e-01, -1.6742e-01,  1.8231e-01, -2.3756e-02,  2.1635e-01,\n","        -3.9786e-02,  1.4516e-01,  6.4602e-01, -1.3777e-01, -7.4153e-01,\n","        -5.2813e-02, -1.9548e-01,  2.2204e-01,  2.4416e-01,  8.8679e-02,\n","         1.9784e-02, -1.4700e-02,  8.4313e-01, -2.3491e-01, -5.5868e-01,\n","        -2.5550e-01, -3.5657e-02, -3.3712e-01,  7.4680e-02,  4.4308e-01,\n","        -3.5202e-01, -1.7683e-01,  2.6548e-01,  1.7615e-01,  2.4520e-01,\n","         3.2222e-01,  7.3771e-01, -8.9655e-02, -4.7036e-01,  1.7352e-01,\n","         2.5446e-01, -2.5499e-01, -3.1070e-01, -4.2068e-01,  6.8420e-02,\n","         5.9285e-01,  2.7942e-01,  3.1292e-01, -3.4782e-02,  1.1248e+00,\n","        -6.2877e-01, -2.1571e-01, -4.9769e-01,  3.1027e-01,  2.5437e-02,\n","        -3.2620e-01, -9.5747e-01, -2.2617e-01,  1.0621e-01,  5.9257e-03,\n","         2.4312e-01, -4.1169e-01,  6.4573e-01, -2.7280e-01,  7.2447e-02,\n","         4.2377e-02, -1.9609e-01, -4.3147e-02,  2.6252e-01, -2.5681e-01,\n","        -1.0660e+00,  1.1151e-01,  3.6309e-01, -1.4482e-01,  2.4801e-01,\n","         1.7198e-01,  3.3486e-01,  3.8915e-01, -1.7384e-01, -2.1994e-01,\n","        -5.5804e-01,  4.1548e-01,  5.0802e-02,  2.1417e-02,  4.2239e-02,\n","         2.6313e-01,  3.3830e-01, -1.7061e-01, -4.4819e-01,  1.5358e-01,\n","         3.3335e-02, -6.4066e-01,  1.2553e-01, -5.4234e-01,  2.3467e-01,\n","         1.7088e+00,  6.0577e-02,  2.1963e-01,  2.1348e-01, -3.8611e-01,\n","        -1.0865e-02, -6.4012e-02,  3.1798e-01, -1.5670e-01,  8.6489e-02,\n","         4.4896e-01, -1.6257e-01, -1.7247e-01, -3.2241e-01,  4.9899e-01,\n","         3.4706e-01,  1.1846e+00, -8.7134e-02,  5.6143e-01, -3.6592e-01,\n","         6.6400e-01,  1.3269e-02,  1.9869e-01, -3.0608e-01,  1.5180e-01,\n","        -3.5065e-01, -4.6388e-01, -1.0272e-01,  6.6855e-02, -4.6275e-01,\n","         2.1146e-01,  3.3848e-02,  4.5386e-02,  4.9994e-01,  7.3799e-02,\n","         3.5940e-01, -3.1096e-01,  9.1181e-02, -6.0122e-01,  9.4338e-02,\n","        -6.9129e-02, -5.9807e-02, -4.9204e-01,  1.4217e-01, -4.9629e-01,\n","        -3.3226e-01,  2.3384e-01, -7.4410e-01,  1.6389e-01, -2.6309e-01,\n","         1.3698e-01,  2.6551e-01,  2.4374e-01,  9.3673e-02, -1.8618e-02,\n","        -6.2619e-01, -3.1830e-01,  5.1256e-01,  2.7765e-01, -6.8511e-02,\n","        -4.3685e-02,  2.9870e-01,  2.8812e-01,  2.0997e-01, -4.2781e-01,\n","         1.5918e-01, -1.3861e-01,  1.0018e-01, -6.8775e-01,  4.7812e-01,\n","        -4.0901e-02, -7.3137e-01,  2.7767e-01, -3.9273e-01, -4.6214e-01,\n","         4.3915e-01, -1.4831e+00, -3.0574e-01, -2.7478e-01,  7.8288e-01,\n","        -1.9797e-01,  5.9390e-01, -4.6977e-01, -2.0054e-01, -1.4004e-01,\n","         1.8939e-01, -1.4663e-01,  7.1023e-02,  3.2586e-01, -6.6349e-01,\n","         2.0955e-01,  9.9898e-02, -7.6429e-01,  4.8232e-01, -4.1603e-01,\n","         1.0888e-01,  8.7007e-01, -2.5240e-01,  1.0048e+00,  6.2590e-02]), 'smile': tensor([-2.5343e-01,  3.6984e-03,  3.4004e-02, -4.0736e-01, -1.7517e-01,\n","        -1.9914e-01,  3.5323e-01, -6.8536e-01,  2.4009e-01, -7.3705e-01,\n","        -1.7443e-01,  2.8733e-01, -4.9960e-01,  4.7402e-01, -8.5256e-02,\n","         3.3492e-01,  1.9661e-01,  1.4715e-02, -1.0327e-01, -4.7470e-02,\n","         5.4236e-01,  7.1168e-01, -1.9575e-01, -1.1399e-01, -6.5099e-01,\n","         3.7597e-01,  2.1726e-01, -1.7413e-01,  8.0706e-01,  2.6025e-01,\n","        -4.5104e-01, -3.0894e-01, -4.0274e-01,  4.0351e-01, -1.0359e+00,\n","         9.8953e-01, -4.2993e-01, -3.4819e-01,  1.2444e-01,  8.5512e-02,\n","        -6.7812e-02, -1.7718e-01,  2.0280e-01,  4.1694e-01,  8.5505e-02,\n","        -5.8034e-02,  3.4705e-01, -2.7768e-01,  1.1476e-01, -4.7884e-01,\n","        -6.6979e-02,  1.2889e-01,  6.5658e-01,  1.8487e-01,  4.3743e-01,\n","         4.7186e-01, -7.2055e-03,  1.2035e-01,  7.0801e-01,  1.4093e-02,\n","         9.1405e-01,  5.4516e-01, -2.9361e-01,  2.1524e-01,  1.5447e-01,\n","        -2.2843e-02, -1.1663e-01,  8.5326e-02,  6.8992e-01, -1.4034e-01,\n","        -3.9930e-01, -1.0763e-01,  3.4674e-01,  2.8916e-01,  7.0884e-01,\n","        -6.4905e-01, -4.7674e-02,  1.0097e-01,  8.4529e-02, -1.8611e-01,\n","         2.1092e-01,  3.0588e-01,  1.6288e-02, -1.4298e-01, -1.2462e-01,\n","         2.9087e-01, -4.9564e-01, -2.2036e-02, -2.1262e-01, -1.1712e-01,\n","        -5.0279e-01, -2.0436e-01, -1.0929e-01, -1.8830e-01, -2.3503e-01,\n","        -3.7536e-01, -2.2646e-01, -5.3052e-01,  3.4169e-01,  3.1534e-03,\n","         5.3879e-01, -3.0415e-01, -2.8927e-02,  5.0076e-01,  3.3222e-01,\n","         4.4228e-01,  3.0189e-01, -2.3317e-01, -4.7961e-01,  2.2161e-01,\n","        -3.4990e-01, -1.3331e-01,  9.6333e-02, -2.8074e-01,  1.8677e-01,\n","         6.8273e-01, -3.4337e-01,  4.7898e-01,  1.4434e-01, -3.3039e-04,\n","        -1.3326e+00, -2.5201e-01,  1.3060e-01,  6.9635e-01,  1.0061e-01,\n","        -6.6632e-01,  5.0885e-01,  2.6519e-01,  7.2094e-02, -1.0256e-01,\n","         4.2499e-01, -4.1019e-01, -9.2909e-03,  3.1094e-01, -3.5543e-01,\n","        -1.1829e-01,  4.7777e-01,  2.3770e-02,  2.7166e-01, -3.4762e-01,\n","         1.9023e-01,  5.1217e-02,  1.3867e-01,  1.3373e-01, -2.4470e-01,\n","         1.9209e-01, -2.5388e-01,  4.1850e-01,  8.8000e-02,  1.2581e-01,\n","        -6.6776e-01, -1.6702e-01, -1.6222e-01,  2.2156e-01,  1.3893e-01,\n","         3.2661e-01,  1.7472e-01, -8.1715e-01, -4.1489e-01,  1.3295e-01,\n","        -1.7243e-01, -1.0923e-01,  5.9114e-01,  4.1328e-01, -2.5987e-01,\n","         3.2112e-01, -4.3269e-01,  4.9642e-01,  4.3494e-01,  2.7719e-01,\n","        -4.0864e-01,  2.0894e-01,  6.5412e-02, -8.8756e-02, -1.3581e-01,\n","        -1.1395e-01,  2.7728e-02, -6.5279e-02,  6.9958e-01, -3.1725e-02,\n","        -1.7863e-01, -1.4293e-01, -8.6776e-02,  4.0905e-01, -5.6835e-01,\n","        -3.5491e-01,  8.1814e-01, -6.1975e-01,  4.5898e-02, -1.3330e-02,\n","        -4.4190e-01, -1.1645e-01, -1.7891e-01,  5.8013e-01, -2.2585e-01,\n","         1.2200e-02, -2.9149e-01, -4.0482e-01,  3.4708e-02,  1.4250e-01,\n","         1.6551e+00,  1.8213e-01,  5.0636e-01,  4.6486e-01,  4.1436e-02,\n","        -2.1946e-01, -1.8982e-02,  3.6610e-01, -4.2413e-01, -4.1800e-01,\n","         2.2674e-01, -5.9502e-01, -2.0986e-01,  1.1665e-01,  2.0304e-01,\n","        -1.3803e-01,  2.2747e-01, -6.9227e-01,  3.3136e-01,  6.7354e-01,\n","         8.5802e-01,  3.7412e-01,  7.0250e-02,  3.4539e-01, -1.9693e-01,\n","         8.0153e-02,  4.1405e-01, -5.4342e-01, -8.7106e-02, -1.2021e-01,\n","         6.6280e-01, -2.9801e-01, -4.2060e-01, -7.5226e-01, -1.2060e+00,\n","        -1.4772e-01, -7.5109e-01, -4.3085e-02, -3.2986e-01,  3.2415e-01,\n","         2.5525e-01,  2.4286e-01, -6.9469e-01,  6.3081e-01,  2.4779e-01,\n","        -2.9404e-01, -4.9388e-01, -1.0459e-01, -1.5177e-01, -2.4889e-01,\n","         1.8699e-01, -9.4593e-01,  2.0859e-01, -5.0324e-02,  1.6560e-01,\n","         5.1836e-01, -4.8495e-02,  4.0203e-01, -3.1279e-01,  5.4975e-02,\n","        -2.1871e-02, -2.8672e-01,  7.1867e-01,  5.3287e-01, -4.9192e-01,\n","        -1.0413e-01, -5.9244e-02, -3.5656e-01,  1.3198e-01,  3.3432e-01,\n","         4.5690e-01, -6.9986e-01,  5.8846e-01, -2.6810e-01,  6.6767e-01,\n","         3.7651e-02, -4.7745e-01,  6.8328e-02, -9.6464e-02,  1.6633e-01,\n","        -7.6280e-02,  3.6285e-01,  9.4321e-02,  5.0601e-01,  3.1811e-01,\n","         4.8938e-01, -3.3238e-01, -3.9497e-01, -1.4957e-01,  4.4434e-01,\n","         2.4984e-01,  3.6308e-01, -7.8423e-01,  1.2721e-01, -2.9141e-01,\n","        -5.0276e-01, -1.8410e-01,  7.3771e-02,  3.4248e-01, -3.4740e-02]), 'frown': tensor([ 0.0666,  0.1538,  0.0625,  0.1581,  0.1805, -0.0907,  0.3796, -0.3293,\n","         0.0698,  0.2430, -0.5350, -0.0195, -0.5180, -0.2556,  0.5683,  0.3399,\n","         0.5196, -0.0792, -0.1926, -0.1749,  0.4813,  0.1342, -0.1796, -0.3452,\n","        -0.8504,  0.2973,  0.6148, -0.1011,  0.5531,  0.1255,  0.0923, -0.0498,\n","         0.1449,  0.3903,  0.0505,  0.9556, -0.7083, -0.1799,  0.2639, -0.1814,\n","         0.1266,  0.0787,  0.2510, -0.8173,  0.0935, -0.2625,  0.3150, -0.0037,\n","         0.0174, -0.3290, -0.3481, -0.2840,  0.5224,  0.1520,  0.2849,  0.0481,\n","        -0.3544,  0.2459,  0.3971,  0.8692,  0.5790, -0.1656,  0.0029,  0.3970,\n","         0.0378,  0.1998, -0.2227,  0.5281,  0.5066,  0.5763,  0.1731,  0.0298,\n","        -0.1765,  0.3423,  0.8381,  0.2386, -0.3294, -0.0828, -0.6339, -0.1962,\n","        -0.0068, -0.6071, -0.3678, -0.2295,  0.2775,  0.0692,  0.2968, -0.3205,\n","         0.4124,  0.4190, -0.7961, -0.0146,  0.2683,  0.0341,  0.0856, -0.5627,\n","        -0.0722, -0.0779, -0.0440,  0.3701,  0.4412, -0.4370, -0.2393,  0.4401,\n","        -0.2679,  0.4099,  0.1353, -0.1171, -0.6894,  0.3529, -0.1995, -0.5854,\n","         0.2990, -0.2084,  0.0117,  0.9022, -0.2072,  0.4824, -0.3126,  0.2424,\n","        -0.4657, -0.3932,  0.3511,  0.8332,  0.1795, -0.3986, -0.1284, -0.3358,\n","         0.4724,  0.0382,  0.2213,  0.0691,  0.1675,  0.1129, -0.3621, -0.6552,\n","         0.1392, -0.0503,  0.1613, -0.6831, -0.1441,  0.3353, -0.2558, -0.1280,\n","         0.2809, -0.3183, -0.4719, -0.1371,  0.0645,  0.1389, -0.9713, -0.2273,\n","        -0.1730, -0.2876,  0.3157,  0.6372,  0.3250, -0.4670, -0.0377,  0.6006,\n","        -0.0409,  0.3174,  0.0225,  0.5385, -0.0746,  0.3668, -0.1682,  0.0705,\n","        -0.0122,  0.0599, -0.1793, -0.0147,  0.0724, -0.7626,  0.0510, -0.2591,\n","         0.1813,  0.4095,  0.3022,  0.4600,  0.0496,  0.1245,  0.1079,  0.6491,\n","         0.0599,  0.0233,  0.9817, -0.4252, -0.1034, -0.7843, -0.2707, -0.3614,\n","        -0.2109, -0.2443, -0.1661, -0.1805, -0.0732, -0.5995, -0.2283, -0.1016,\n","        -0.0233,  0.3732,  0.3214,  0.0431,  0.5023,  0.3398,  0.0035,  0.2064,\n","        -0.0703,  0.1248,  0.1763,  0.2317,  0.0116,  0.4340, -0.0800, -0.0786,\n","         0.2266,  0.0634,  0.0656,  0.0430, -0.1879,  0.5930,  0.6504, -0.2770,\n","        -0.2575,  0.1686,  0.6410,  0.1380,  0.4968, -0.0757,  0.1743, -0.0342,\n","        -0.0395, -0.0586, -0.3263, -0.2597, -0.3083, -0.1954,  0.1446, -0.3972,\n","         0.0718,  0.4113, -0.0354,  0.0544, -0.0641,  0.7524, -0.5703, -0.6032,\n","        -0.1807,  0.0681,  0.1052, -0.4045,  1.0202,  0.6610, -0.1728,  0.2351,\n","        -0.3661,  0.2644, -0.2364,  0.2709, -0.2419,  0.1776,  0.6543, -0.1925,\n","         0.2098, -0.5019,  0.0111,  0.0288, -0.3675,  0.8338,  0.5740,  0.0719,\n","         0.6179,  0.1217,  0.2045,  0.1785,  0.4945, -0.1377,  0.0317,  0.0385,\n","        -0.1314, -0.2065, -0.2094,  0.5859,  0.1655, -0.1042, -0.0588,  0.1678,\n","         0.2201,  0.2779,  0.0597,  0.0687, -0.4872, -0.0083, -0.6284, -0.7142,\n","         0.3352, -0.1646,  0.5143, -0.3653]), 'race': tensor([ 0.3772,  0.0943, -0.0920, -0.2854, -0.4566,  0.3018,  0.2752, -0.6025,\n","         0.6195, -0.7371,  0.6872,  0.1035, -0.1692,  0.0318,  0.0329, -0.0109,\n","         0.3969,  0.7991, -0.0552, -0.1608,  0.1589,  0.0677, -0.0915,  0.3662,\n","        -0.3291, -0.8320,  0.1730,  0.2153, -0.2767, -0.8369, -0.4862, -0.3073,\n","         0.1076, -0.7042, -1.7540,  0.5964, -0.2087, -0.1276, -0.1796,  0.5399,\n","        -0.2308,  0.1319,  0.3613, -0.7014,  0.0195,  0.2744, -0.1349,  0.3570,\n","         0.3997,  0.2948, -0.3131, -0.1312,  0.2933, -0.2065,  0.1110,  0.4446,\n","         0.0181, -0.7459,  0.1480,  0.1715, -0.0300,  0.4419,  0.1950, -0.0280,\n","         0.2220, -0.6955,  0.0962,  0.2054,  0.1805, -0.8686, -0.2681,  0.1603,\n","         0.0193, -0.4585, -0.4085, -0.2488,  0.1302, -0.0654, -0.1683, -0.1212,\n","        -0.0938,  0.1751,  0.2292,  0.6293, -0.8823, -0.1457, -0.0404, -0.1286,\n","         0.5673,  0.8281,  0.1154, -0.6294,  0.5890, -1.0381,  0.4758, -0.0867,\n","        -0.2752,  0.5202, -0.3793, -0.4739,  0.2173,  0.3244, -0.0278, -0.1212,\n","        -0.1288,  0.0588, -0.1154, -0.3649, -0.2339,  0.3246, -0.3399, -0.2211,\n","        -0.1574,  0.2254, -0.0847,  0.0448,  0.0238,  0.0997, -0.0595, -0.2571,\n","        -0.1864, -0.1445, -0.1961, -0.3609,  0.3230,  0.2502,  0.3210,  0.4229,\n","        -0.2622, -0.2628, -0.1383, -0.1334,  0.3448,  0.6729, -0.0864,  0.1836,\n","         0.0495, -0.5968,  0.3963,  0.3714, -0.2147, -0.1491,  0.1253, -0.0573,\n","         0.1869, -0.3192, -0.1914, -0.1096, -0.3258,  0.9220,  1.0750,  0.7282,\n","        -0.0316, -0.1520, -0.0570, -0.7809, -0.2556, -0.1131,  0.2080,  0.1668,\n","        -0.1276, -0.4322, -0.2967, -0.1786,  0.1370, -0.0294, -0.2007, -0.1451,\n","         0.1515, -0.2878,  0.4900,  0.4071, -0.2948, -0.4969,  0.3094, -0.4720,\n","         0.0312, -0.1234, -0.0380,  1.0628,  0.1115,  0.8282,  0.4395,  0.4407,\n","         0.2375, -0.6317,  0.1054,  0.2325,  0.1714,  0.2890, -0.3783, -0.5051,\n","        -0.1292,  0.4092,  0.3275, -0.2668, -0.0405,  0.0857,  0.1265, -0.3315,\n","         1.4855, -0.2467,  0.0131, -0.3105,  0.4395,  0.0719,  0.0504, -0.3185,\n","         0.1926,  0.3220, -0.1423, -0.3587,  0.3826, -0.9420, -0.3986, -0.0388,\n","        -0.3159, -0.2967,  0.8525, -0.2729,  0.2253, -0.4645,  0.0324, -0.5164,\n","         0.8473, -0.2370,  0.2905, -0.1019, -0.6863,  0.7789,  0.0298, -0.4917,\n","         0.1021,  0.0718,  0.1341,  0.0529, -0.0420, -0.0292,  0.2827,  0.5730,\n","         0.0691, -0.1984,  1.0238,  0.2167, -0.8799, -0.2769, -0.0798,  0.5300,\n","         0.4964,  0.2023, -0.6365, -0.0487, -0.5578,  0.1650,  0.2619, -0.4789,\n","         0.1983, -0.5208,  0.2836,  0.5890,  0.3954, -0.6423, -0.6251,  0.3019,\n","         0.1970,  0.1086,  0.4622, -0.3110,  0.5150,  0.1253,  0.0452,  0.1860,\n","        -0.0312,  0.6919,  0.0534,  0.1245, -1.6452,  0.3708,  0.9722,  0.2728,\n","         0.0550, -0.1541,  0.3870, -0.0026, -0.2408, -0.2431, -0.2867, -0.0247,\n","        -0.0748, -0.3344, -0.2924,  0.0841, -0.4523,  0.4696, -0.3864, -0.0601,\n","        -0.3074,  0.0759, -0.1619,  0.5268]), 'stroll': tensor([-2.6833e-01, -3.7851e-01, -5.7686e-02,  5.4270e-01,  1.6212e-02,\n","        -6.6792e-02,  5.3039e-02, -8.4728e-01,  5.4269e-01,  4.6961e-01,\n","        -4.8449e-01, -5.3468e-01, -4.3233e-01, -3.9125e-01, -5.7616e-02,\n","        -2.1712e-02, -1.7758e-02, -1.8028e-01,  1.3036e-01,  5.7410e-01,\n","        -3.6061e-02,  1.4551e-01,  2.3765e-01, -4.2077e-02, -9.1777e-02,\n","        -4.5660e-01,  1.3171e-01, -1.2563e-01, -2.3006e-01,  7.8735e-02,\n","         6.0844e-01, -1.2775e-01,  3.7850e-01, -1.8701e-01, -4.8340e-01,\n","         4.2431e-01, -6.4592e-02, -2.6280e-01, -3.5539e-01, -2.7315e-01,\n","        -9.1098e-03,  6.0631e-01, -3.9088e-01,  1.5949e-01, -1.0174e-01,\n","         4.1744e-02,  1.5650e+00, -1.1396e-01, -1.9953e-01,  1.8235e-02,\n","        -5.7385e-01, -4.3299e-01,  5.7945e-01, -5.1709e-02,  3.7820e-01,\n","         4.4386e-02,  1.2654e-02, -6.8095e-01,  2.1457e-01,  6.6663e-01,\n","         2.6215e-01, -2.0718e-01,  4.2253e-01,  7.0697e-01,  1.5965e-01,\n","         3.0785e-01,  1.8293e-01,  3.8529e-01,  1.1112e-01, -8.1914e-01,\n","         1.1493e-01,  1.4276e-01,  4.8107e-02, -3.1896e-01,  3.1233e-01,\n","         1.5533e-01,  1.0236e-01,  1.3525e-01,  6.6385e-01, -7.5792e-01,\n","        -4.5952e-01,  3.1524e-01, -2.0607e-01,  8.3719e-02,  2.1077e-01,\n","        -2.1237e-01, -5.1817e-01,  2.9231e-01,  4.2101e-01,  3.0286e-01,\n","         2.4410e-01, -3.3379e-01,  6.2201e-01, -7.3376e-02,  1.3784e-01,\n","         5.6704e-02,  4.3318e-01, -4.1417e-01, -8.8332e-02,  3.6355e-01,\n","         4.5502e-01,  2.3933e-01, -3.2592e-01,  3.2980e-01, -1.7007e-01,\n","         2.4712e-01,  1.1968e-01, -3.3002e-01,  1.3925e-01, -3.0268e-01,\n","        -8.8174e-02,  1.5014e-01,  2.1852e-04, -1.3035e-01,  1.5476e-01,\n","         7.4927e-01,  4.6464e-01,  2.2620e-01, -1.6991e-01, -7.9758e-02,\n","        -1.6114e-01,  8.2962e-02,  2.8825e-01,  1.5562e-01,  1.1692e-01,\n","         4.5690e-01,  5.9780e-01, -1.4991e-01, -6.0359e-02, -4.9332e-02,\n","         8.9208e-02,  9.5147e-02,  1.0495e-01,  2.8549e-01,  2.7330e-03,\n","         3.4190e-01,  9.1249e-02, -3.7056e-01,  9.8005e-02, -9.8085e-02,\n","        -3.7883e-01, -2.0285e-01,  1.8858e-01,  8.1935e-01,  8.0300e-02,\n","        -5.5025e-02, -2.7193e-01,  4.3352e-02, -1.2656e-01,  2.0056e-01,\n","        -7.8188e-01,  1.6860e-01,  3.5878e-01,  2.3426e-01,  5.2705e-01,\n","        -2.1677e-01, -3.1644e-01,  3.5959e-02,  3.5097e-01,  1.6965e-01,\n","        -3.4970e-01, -1.1197e-01,  2.8682e-01, -4.0265e-01, -1.1558e-01,\n","         1.6769e-01,  4.0141e-01,  6.1206e-02,  4.0224e-01, -2.3165e-01,\n","        -5.7440e-01, -5.4471e-01,  1.4153e-01,  2.2486e-02, -3.2986e-01,\n","        -3.1706e-01, -4.9966e-01,  7.0256e-01,  2.4980e-02, -3.7240e-01,\n","        -1.4273e-02,  1.7255e-01, -2.3103e-01,  2.0839e-01,  3.3017e-01,\n","         6.0412e-01,  3.8011e-01, -1.4641e-01, -1.7063e-01,  2.0912e-01,\n","        -5.7139e-01, -2.9506e-02, -4.1074e-01, -4.7858e-01, -4.2806e-01,\n","         1.6718e-01, -4.8910e-02, -2.6181e-01, -6.4407e-02, -3.1428e-01,\n","         4.0032e-01, -1.8094e-01, -3.2488e-01,  2.6876e-01,  3.8422e-01,\n","         1.3847e-02, -2.9584e-01, -1.8602e-01, -4.2194e-01, -1.0982e-01,\n","        -1.5272e-01, -1.9533e-01, -3.7276e-01,  1.9518e-01, -6.0348e-01,\n","        -7.1079e-02,  1.2676e-01, -4.1775e-01, -1.4228e-01, -1.9666e-01,\n","         8.4802e-01,  3.7101e-03, -9.7121e-01,  1.5430e-01, -7.3064e-01,\n","         6.1967e-02,  5.7693e-01, -1.6985e-01, -8.0856e-02, -1.2974e-01,\n","        -6.6582e-02,  2.6398e-01, -1.6891e-01, -4.1755e-01,  5.1946e-01,\n","         1.2126e-01, -1.5181e-01, -2.0798e-01, -4.7277e-01, -3.2199e-01,\n","         4.6477e-01,  1.1297e-03, -5.0069e-01, -1.6860e-02, -7.4487e-02,\n","         3.2228e-01, -1.6319e-02,  3.9260e-01, -5.8199e-02, -2.0800e-01,\n","         6.3469e-01, -5.9993e-01,  5.1624e-01, -2.3849e-01, -1.5122e-01,\n","        -1.9870e-01,  1.2665e-01,  2.3279e-01, -9.3928e-02, -2.4822e-02,\n","         3.7970e-01, -1.8415e-01,  4.7046e-01, -2.3489e-01, -3.9768e-01,\n","        -3.1916e-01, -8.0561e-02, -1.4978e-01,  3.3226e-01, -2.4514e-01,\n","         3.0883e-01, -2.4254e-01,  4.6060e-01, -2.6805e-01,  1.8775e-01,\n","        -2.5753e-01, -6.3417e-01,  1.4610e-01, -3.0250e-01, -1.2945e-01,\n","        -4.8141e-02, -1.5352e-01,  7.5601e-01, -4.9975e-01, -2.2159e-01,\n","         2.1641e-02,  3.1790e-01,  3.7651e-01, -2.4436e-01, -2.8061e-01,\n","         2.9316e-01,  3.0531e-01, -5.6859e-01,  6.6181e-01,  1.2128e-02,\n","        -5.9440e-01, -1.4940e-01,  8.2552e-01, -2.0248e-01, -1.9058e-01]), 'tiny': tensor([-0.5125,  0.0790, -0.3232, -0.2119,  0.0839,  0.0843, -0.0747, -0.1402,\n","         0.7715, -1.0180, -0.3326,  0.0642, -0.0645,  0.2696,  0.4171,  0.7300,\n","        -0.1467, -0.0397, -0.0078, -0.2534,  0.2438,  0.4685,  0.3018,  0.4956,\n","        -0.4249, -0.3664,  0.0243, -0.0819, -0.2208, -0.0397, -0.2868,  0.1510,\n","        -0.5763,  0.7287, -0.0586,  0.5063, -0.1968,  0.3240,  0.0988,  0.0833,\n","        -0.3729, -0.2003,  0.1067,  0.1893,  0.3087, -0.3721, -0.1461, -0.2010,\n","         0.2021,  0.3696,  0.2824,  0.2728,  0.6246,  0.0375, -0.2579, -0.3171,\n","        -0.1403, -0.3569,  0.6081, -0.2663,  0.0912, -0.2940,  0.7276,  0.1532,\n","         0.6009,  0.0709,  0.1083,  0.5397, -0.0729,  0.0669, -0.1201,  0.1226,\n","         0.1185,  0.0131, -0.3611,  0.1040, -0.3102, -0.5346,  0.0608, -0.4784,\n","        -0.0538,  0.1364, -0.2747,  0.3927,  0.0856,  0.0568,  0.1637, -0.0448,\n","        -0.3422, -0.1996,  0.2654,  0.0369, -0.5277, -0.3512,  0.2411, -0.1100,\n","         0.3347,  0.2026, -0.1456,  0.1263,  0.3430,  0.4028, -0.1912, -0.7516,\n","        -0.5005,  0.2500,  0.4623, -0.2900,  0.2155, -0.0201, -0.2010,  0.3635,\n","         0.1699,  0.0128, -0.0840, -0.2155,  0.1304,  0.5611,  0.2244,  0.3697,\n","         0.1350, -0.0138,  0.4484,  0.1045, -0.1757,  0.3184, -0.2199,  0.3321,\n","         0.0916,  0.2082, -0.0083, -0.2404, -0.1779,  0.4387,  0.4627, -0.1246,\n","         0.4791,  0.4058, -0.1890, -0.5515,  0.2461,  0.1782, -0.2804, -0.1122,\n","        -0.5427, -0.1867,  0.1761,  0.0074,  0.1009, -0.1844,  0.0679, -0.5788,\n","        -0.2275, -0.3619,  0.6290,  0.2181, -0.3140,  0.4845, -0.1862,  0.0716,\n","         0.2989,  0.3125,  0.6705, -0.1328, -0.0216, -0.3851,  0.2137, -0.0588,\n","         0.1682, -0.1463, -0.1991, -0.2564, -0.0181,  0.1787, -0.4076, -0.4130,\n","        -0.1388,  0.6458,  0.2118, -0.0375,  0.2298, -0.2195,  0.2637,  0.2598,\n","         0.3967, -0.3397,  0.7720, -0.1849, -0.2044, -0.1530,  0.5836,  0.0584,\n","         0.0960,  0.0572,  0.3853,  0.3484,  0.4510, -0.0569, -0.5913,  0.1508,\n","         1.2242,  0.1117, -0.0125,  0.3767, -0.0028, -0.5667, -0.2825, -0.0215,\n","        -0.3680,  0.3892,  0.1361,  0.4091,  0.3090,  0.0617,  0.3734,  0.3164,\n","         0.9152, -0.4571, -0.5378,  0.3538,  0.3454,  0.2052, -0.3025,  0.0898,\n","         0.2764, -0.3171, -0.0404, -0.1750, -0.3273, -0.0677,  0.2099, -0.6289,\n","        -0.2008,  0.0916,  0.3768,  0.1925,  0.2766, -0.0207,  0.0505, -0.3760,\n","         0.2410, -0.2518,  0.1454,  0.5300, -0.5081, -0.7375,  0.3246,  0.2047,\n","        -0.6377, -0.3988, -0.2406,  0.0412,  0.0223, -0.4778,  0.6542,  0.5956,\n","         0.1078, -0.1485, -0.2389,  0.0475,  0.3668, -0.1745,  0.0032, -0.3650,\n","         0.4757, -0.3734, -0.1185,  0.2050, -0.1271,  0.5150, -0.3328,  0.5074,\n","        -0.1680, -0.1733, -0.4454,  0.2508, -1.7673,  0.2228, -0.9117,  0.0410,\n","        -0.2526,  0.8084, -0.3504, -0.0677, -0.3208, -0.3375, -0.1057,  0.0538,\n","        -0.4065, -0.0522,  0.0969, -0.2300,  0.1653,  0.0828, -0.7183,  0.7596,\n","         0.3504,  0.0389, -0.0521, -0.2072]), 'huge': tensor([ 8.6357e-03,  4.3235e-02,  1.0827e-01, -4.9339e-01,  3.1105e-02,\n","         3.4536e-01,  4.4176e-01,  1.0609e-01, -2.6873e-01, -1.2102e+00,\n","        -5.6915e-03,  2.4460e-01, -4.0036e-01,  1.0162e-01,  5.0523e-02,\n","        -1.0094e-01, -1.7821e-01,  8.8620e-02, -2.6005e-03,  1.2686e-01,\n","         1.7620e-01, -2.8074e-02,  4.2711e-01, -1.1745e-01, -1.9838e-01,\n","         4.2144e-01,  2.0365e-01, -1.8929e-01,  1.2053e-01,  1.4749e-01,\n","        -5.5195e-01,  6.8032e-02, -8.0044e-01,  4.0569e-01, -8.0702e-01,\n","         6.2938e-02, -6.3124e-01, -1.2953e-01,  8.2317e-02,  3.7490e-01,\n","        -9.3021e-02, -4.6155e-01,  2.8764e-01,  1.4898e-01, -2.5789e-01,\n","         6.2966e-02,  3.6248e-01, -4.9638e-01,  4.7431e-01, -2.2802e-02,\n","         2.1250e-01,  2.5498e-01, -4.6309e-01, -1.8572e-01, -1.1483e-01,\n","         3.7144e-02, -2.1351e-01,  1.7997e-01,  1.9043e-01,  1.9052e-01,\n","        -1.9411e-01, -1.4760e-01,  2.8354e-01, -2.6713e-02,  1.5452e-01,\n","         1.5698e-01, -3.5686e-01,  3.1554e-01, -2.7853e-01,  1.2966e-01,\n","        -1.9950e-01,  1.5775e-01, -5.4403e-03,  1.9505e-01,  5.0371e-02,\n","        -1.1546e-01, -6.5471e-02, -4.1852e-01,  4.7905e-01, -1.5148e-01,\n","         3.3128e-03, -5.2826e-02, -3.8306e-02, -3.7548e-01,  3.8729e-01,\n","         3.0702e-01,  2.7787e-01,  6.3588e-02,  2.3237e-01, -2.9726e-01,\n","         3.8948e-01, -6.9028e-02, -3.7375e-01, -2.6925e-01, -2.3868e-01,\n","        -1.3045e-01,  8.0642e-02, -4.2701e-01, -5.5988e-02, -1.8420e-01,\n","         5.1868e-02,  3.6562e-01, -2.7225e-01, -3.8476e-01, -1.4819e-02,\n","         3.3410e-01,  6.7213e-02,  5.5812e-02, -2.2293e-01, -2.9961e-01,\n","        -4.0603e-01, -1.0227e-01, -1.8371e-01, -1.9185e-01,  5.5083e-01,\n","        -3.8031e-02,  1.8114e-01,  5.3981e-01,  1.8531e-01, -8.2432e-01,\n","         3.2445e-01, -1.5077e-01, -3.6299e-02,  5.2321e-01,  4.4995e-01,\n","        -2.9969e-01, -2.1504e-01,  1.2946e-01, -4.1237e-01, -1.0684e-01,\n","         1.6105e-01,  5.3389e-01, -6.1251e-01,  3.6016e-02,  3.5416e-01,\n","        -1.2595e-01, -3.0893e-01, -1.1018e-01,  5.2400e-02,  2.9359e-01,\n","        -5.8381e-01, -1.3266e-01,  2.4751e-01,  1.8416e-01,  3.1853e-02,\n","        -8.5407e-02,  3.2910e-01,  1.0529e-01,  1.7547e-01, -1.2813e-01,\n","         2.1846e-02,  1.4542e-01, -4.3317e-01, -2.8386e-01,  3.2729e-01,\n","         4.2720e-01,  1.0364e-01,  1.4055e-03, -4.6143e-01, -2.6617e-01,\n","        -1.7617e-01,  3.4414e-01,  5.9322e-01,  3.4927e-01, -6.3241e-02,\n","        -4.2426e-01,  4.0006e-01, -6.8298e-02, -1.8127e-01,  9.8750e-02,\n","        -8.3963e-03, -4.5381e-01, -1.6327e-01, -1.0494e+00,  2.0422e-01,\n","         1.1796e-01, -1.1975e-01,  4.0332e-01,  6.0662e-01,  2.4351e-01,\n","         1.9871e-01, -2.8070e-01,  4.1751e-01, -1.7294e-01, -8.6260e-02,\n","        -5.9442e-03,  2.2286e-01,  1.1404e-01, -1.4344e-01, -6.5506e-03,\n","         2.9894e-01,  2.8289e-01, -1.9881e-01, -1.6811e-01,  5.5211e-01,\n","        -7.3004e-02,  2.2586e-01,  3.3048e-01,  1.7152e-01,  2.1694e-01,\n","         9.6064e-01, -9.6082e-02, -3.6114e-01, -3.2137e-01,  1.2551e-01,\n","        -7.7926e-02, -1.0100e-01,  2.7960e-01,  2.3127e-01, -2.5155e-01,\n","        -2.1470e-01,  1.3666e-01, -2.1242e-01, -5.0837e-01,  3.0708e-01,\n","         3.3197e-01,  4.8487e-02,  3.2034e-02,  1.7840e-02,  4.5661e-01,\n","         5.7171e-01,  2.5506e-01,  1.7098e-01, -3.5194e-01, -4.0788e-02,\n","        -3.5040e-01, -2.5864e-01,  2.9303e-02,  2.9131e-02, -3.5019e-01,\n","        -6.2727e-02, -8.1382e-02, -2.3785e-01,  1.0131e-01,  3.1063e-03,\n","         5.6327e-02,  5.1677e-02, -8.4361e-02,  5.2546e-02, -3.3672e-01,\n","         4.6861e-01,  1.6575e-01,  1.5693e-01,  4.6876e-02, -1.2912e+00,\n","        -5.3440e-01,  1.2209e-01,  1.8767e-02,  3.4394e-01, -2.2248e-01,\n","        -1.4216e-02, -4.7931e-02,  7.3819e-02, -4.2696e-01,  6.5873e-01,\n","        -1.7101e-01, -9.7068e-01, -4.5458e-01, -3.8364e-01, -7.1835e-02,\n","         2.2140e-01,  3.5827e-02,  7.3099e-01,  4.0068e-01,  4.7924e-01,\n","        -1.2367e-01, -6.8901e-02, -4.3715e-02, -4.5528e-03, -2.0325e-01,\n","         1.5467e-01,  6.0664e-02, -1.5029e-01, -9.2427e-02,  9.4104e-02,\n","        -1.6602e-01, -2.1285e+00,  2.2896e-01,  3.4308e-02, -1.5880e-02,\n","        -4.8699e-01,  6.0481e-01,  2.5118e-01,  1.2722e-01,  1.2704e-01,\n","        -4.3266e-02, -3.8210e-01,  1.3129e-01,  1.7560e-01,  1.0326e-01,\n","         6.0574e-02,  3.2299e-01, -7.0140e-03,  4.1416e-01,  3.6695e-01,\n","         5.1440e-01,  1.7696e-01, -1.3105e-01, -3.7013e-01, -4.5786e-01]), 'soft': tensor([ 0.0491,  0.1317, -0.0120, -0.2499, -0.3706, -0.2045,  0.2529,  0.3264,\n","         0.5392, -1.2627,  0.0549, -0.8583, -0.3941,  0.4991,  0.3780, -0.4232,\n","        -0.2662,  0.2906,  0.0329,  0.4473, -0.0685,  0.4969,  0.0334,  0.2513,\n","        -1.0642, -0.1399, -0.3716,  0.1954, -0.0448,  0.2230, -0.6590,  0.4482,\n","        -0.2907, -0.1156, -0.8645,  0.6931,  0.7123,  0.2546, -0.1183,  0.3759,\n","         0.3205,  0.5220,  0.5014, -0.2099,  0.2751,  0.2110,  0.3664, -0.0859,\n","        -0.2421,  0.4385, -0.4184,  0.5062,  0.0973,  0.0496, -0.1996,  0.0442,\n","        -0.1956, -0.2806,  0.5274,  0.1150,  0.7425,  0.0744, -0.0164, -0.2625,\n","        -0.1191, -0.5240,  0.1921, -0.0192,  0.2839,  0.5607, -0.0786,  0.2105,\n","         0.0868,  0.3156,  0.6461, -0.1978,  0.2220,  0.0371,  0.1271, -0.0305,\n","         0.3374, -0.1764, -0.4665, -0.0286,  0.1595,  0.0423, -0.0674, -0.0072,\n","        -0.4960,  0.2480,  0.4606,  0.0450, -0.3745,  0.1024, -0.0900,  0.4664,\n","        -0.3415,  0.4061, -0.0682,  0.1779,  0.1611, -0.0417, -0.4821,  0.1487,\n","        -0.7146, -0.0069, -0.5567, -0.1057, -0.1811, -0.0800,  0.3882, -0.2044,\n","         0.3765, -0.2709,  0.2862, -0.2047, -0.4010,  0.4877, -0.2908, -0.2068,\n","        -0.3891, -0.2544,  0.4804,  0.4690, -0.6193,  0.2594,  0.1701,  0.5099,\n","        -0.1123, -0.1027, -0.0516,  0.6327, -0.0046,  0.1717, -0.2183,  0.2162,\n","        -0.2353,  0.5108,  0.0392,  0.0430,  0.2977, -0.2205,  0.0843, -0.3753,\n","        -0.2295, -0.0110, -0.4369, -0.2081,  0.3945, -0.1404,  0.0041, -0.4736,\n","         0.0560,  0.1064, -0.2404, -0.4037, -0.1412, -0.7583,  0.0558, -0.0897,\n","        -0.4249, -0.2057, -0.1706,  0.0425,  0.1572, -0.3239, -0.2050,  0.1944,\n","         0.5096,  0.3443, -0.3469, -0.1267, -0.2826,  0.1467, -0.6294, -0.3349,\n","         0.5176,  0.0979, -0.1619,  0.2168,  0.0648, -0.4676,  0.1393,  0.1911,\n","        -0.3268, -0.1915,  1.1419, -0.0679,  0.4482, -0.2702,  0.4054,  0.5695,\n","        -0.0807, -0.0946,  0.0062,  0.0720, -0.1929,  0.5645,  0.1681,  0.2882,\n","         0.9135,  0.1387,  0.4934,  0.1539, -0.1488, -0.4411, -0.2903,  0.5898,\n","        -0.7236,  0.1945,  0.4913,  0.0304,  0.2363, -0.0021, -0.1704,  0.2991,\n","         0.1462, -0.5791, -0.1875, -0.1421,  0.5239,  0.3984,  0.0366, -0.2125,\n","        -0.2850,  0.2006, -0.0122,  0.0419, -0.1260, -0.3367,  0.4123, -0.1407,\n","        -0.0572,  0.3460, -0.1047,  0.0958, -0.3479,  0.2827, -0.8711, -0.5434,\n","        -0.0026, -0.4459, -0.3448, -0.3442, -1.1303,  0.1626,  0.2592, -0.2979,\n","        -0.3695, -0.4814,  0.0945, -0.1178, -0.3297,  0.1131,  0.1991, -0.2507,\n","        -0.1098, -0.1449, -0.2711,  0.2775, -0.2524, -0.3339, -0.4764,  0.4284,\n","        -0.1064, -0.4672,  0.5023,  0.1028,  0.1249,  0.3706,  0.1828, -0.2767,\n","        -0.5783,  0.1937, -0.0788,  0.0649, -1.1989,  0.4230, -0.8325, -0.1887,\n","         0.0994, -0.1272, -0.0274,  0.3019,  0.0691,  0.1916,  0.0762,  0.1108,\n","         0.0082, -0.2603, -0.3443,  0.5056, -0.1423,  0.5779, -0.1710,  0.2691,\n","         0.1238,  0.3281, -0.4660,  0.3778]), 'rough': tensor([-0.0722, -0.4951, -0.4364,  0.2545, -0.8853,  0.2739,  0.2235,  0.9330,\n","         0.1391, -0.8909, -0.3865,  0.1933, -0.1196,  0.4418, -0.5069,  0.1143,\n","        -0.0814,  0.3458,  0.2829,  0.3492, -0.3494,  0.2758, -0.0563,  0.2145,\n","        -0.4430, -0.0947,  0.3839,  0.0849, -0.0292,  0.7554,  0.0528,  0.4582,\n","        -0.4333, -0.0309, -0.6416,  0.4712, -0.1685, -0.2741, -0.3124, -0.3701,\n","        -0.1318,  0.1246,  0.6732, -0.4597,  0.2477,  0.2659, -0.0380, -0.2543,\n","        -0.6279, -0.1216, -0.1874,  0.0496,  0.1094,  0.1355, -0.0271, -0.0823,\n","        -0.6539, -0.2535, -0.0876,  0.2267, -0.1030,  0.1174,  0.0570, -0.3601,\n","        -0.1797, -0.5179,  0.3410, -0.1203,  0.3275, -0.2780,  0.2206,  0.3467,\n","        -0.7439, -0.1266, -0.1382,  0.0733,  0.1523,  0.1088,  0.0049, -0.3104,\n","        -0.1615,  0.0092,  0.8578,  0.0968, -0.2820, -0.0245,  0.4776, -0.2531,\n","        -0.0708,  0.2548, -0.1454,  0.5278, -0.4906, -0.5000,  0.0877, -0.0247,\n","         0.0827,  0.0250, -0.0548, -0.5165, -0.2762,  0.2427, -0.3521,  0.3244,\n","        -0.6081,  0.5074, -0.0086, -0.1796, -0.0014, -0.4022,  0.1087, -0.5044,\n","         0.1567, -0.2561, -0.2212,  0.2053,  0.3251,  0.0270,  0.0200,  0.2811,\n","        -0.1655, -0.5296, -0.1447,  0.4246, -0.0260,  0.5143,  0.4834,  0.0484,\n","         0.1362, -0.4859,  0.0797,  0.7534, -0.0195, -0.0851, -0.0981,  0.1143,\n","         0.0778, -0.1892, -0.2216,  0.0591,  0.4205,  0.7917, -0.5321,  0.1075,\n","        -0.1443, -0.2290,  0.1701, -0.2104,  0.2600, -0.0049, -0.1956,  0.0210,\n","        -0.3898, -0.1292, -0.1074, -0.0252, -0.1508,  0.1645,  0.6269,  0.5965,\n","        -0.3219, -0.4364, -0.3663, -0.2767,  0.3173, -0.3446,  0.3030,  0.1124,\n","        -0.3546,  0.0867, -0.3919, -0.1187, -0.6392,  0.1089, -0.4219, -0.0338,\n","         0.1612,  0.2802, -0.5638, -0.5723, -0.1075,  0.2306,  0.1212,  0.0524,\n","        -0.0983, -0.3529,  0.3537, -0.0061, -0.1021,  0.4659, -0.2772,  0.5555,\n","         0.7957, -0.3090,  0.4803, -0.1448, -0.5376, -0.0150, -0.0742, -0.1930,\n","         1.2361,  0.3712,  0.5683,  0.3442,  0.4908,  0.2470, -0.1185,  0.6376,\n","        -0.3024,  0.0372, -0.0033,  0.2332,  0.1105, -0.3767, -0.6337,  0.1712,\n","         0.6190, -0.2664, -0.3196, -0.2429,  0.8689,  0.0671,  0.0156, -0.1438,\n","        -0.0247,  0.1501,  0.4388, -0.8679, -0.4982, -0.3466,  0.2761, -0.2710,\n","        -0.5903, -0.2704,  0.1142, -0.1558, -0.3455, -0.1535,  0.2192,  0.1166,\n","         0.0256,  0.0444,  0.0272, -0.1824, -0.4608, -0.1878, -0.1743,  0.3745,\n","        -0.0201,  0.2535, -0.2488, -0.3321, -0.1464, -0.8128,  0.3379,  0.3073,\n","         0.2237, -0.0208, -0.2384,  0.5920, -0.3356,  0.6299, -0.7644, -0.0146,\n","         0.1991,  0.5521,  0.0033, -0.3993, -0.3179, -0.0823, -0.3001, -0.3536,\n","         0.0482, -0.2908,  0.1165,  0.2739, -0.7527,  0.0651, -0.0800, -0.0318,\n","        -0.1593,  0.0941,  0.0797,  0.4220,  0.1933, -0.4389,  0.2616, -0.0749,\n","         0.2172, -0.2079, -0.1825,  0.5726, -0.2005,  0.4527,  0.4183,  0.6613,\n","        -0.1028,  0.2370,  0.3469,  0.1195]), 'team': tensor([-2.7011e-02,  1.1299e+00,  4.4708e-02, -4.0380e-01, -4.7284e-02,\n","         9.2736e-02, -2.0715e-01,  2.6137e-01,  2.4730e-01, -8.8769e-01,\n","         3.1309e-01, -1.4940e-01,  4.9929e-03, -1.1520e-01, -1.7990e-01,\n","         6.4681e-01,  1.5044e-01, -3.4580e-01,  2.3370e-03, -7.5788e-01,\n","         1.6048e-01, -2.9066e-02,  1.7194e-01, -4.2799e-02,  3.4297e-02,\n","        -1.1400e-01, -2.1149e-01,  3.6118e-01, -3.3393e-01, -1.3581e-01,\n","         1.7858e-01, -2.3381e-01, -8.3367e-02,  1.0626e-01, -1.7301e+00,\n","         5.2052e-01,  3.7855e-01,  5.5852e-01, -1.0172e-01, -1.8644e-01,\n","        -1.2096e-01, -5.2009e-02,  1.9565e-01, -1.2685e-01, -3.7493e-01,\n","         9.7457e-02,  1.7014e-01,  7.7521e-02, -2.1946e-01,  1.4490e-01,\n","         1.2733e-01, -2.2223e-01, -3.1548e-01,  1.1137e-01, -4.0263e-01,\n","         8.3553e-01, -7.5475e-03,  3.6725e-01,  1.2324e-02, -1.0033e-01,\n","        -6.0014e-01,  4.2763e-01, -2.4048e-01, -2.8162e-01,  4.6409e-02,\n","        -3.7942e-01, -8.0836e-02, -3.2884e-01, -9.3836e-02, -8.6769e-01,\n","        -8.4826e-02,  4.7311e-01, -2.7073e-01,  2.0990e-01, -7.5609e-01,\n","         1.1649e-01,  4.5235e-01, -2.6045e-01,  5.2206e-02,  3.4906e-01,\n","        -5.9366e-02,  3.9424e-01, -6.6567e-02, -1.2907e-01, -2.1789e-01,\n","         5.1554e-02, -1.4604e-01, -5.6169e-02,  3.1792e-01,  1.9815e-01,\n","         1.7534e-01,  9.6423e-01,  4.8888e-01, -5.6890e-01,  2.1305e-01,\n","        -8.8585e-02, -5.3623e-01, -2.9281e-01, -1.1353e-01, -7.2363e-01,\n","         7.0515e-02,  1.0510e-01, -1.7852e-02,  7.1786e-02,  4.1699e-01,\n","        -8.2320e-02,  5.6089e-01,  5.4537e-02,  1.1426e-01,  4.2515e-01,\n","         2.3246e-01, -5.9402e-02, -2.7655e-01, -3.3986e-01,  1.5653e-01,\n","         2.0869e-01, -2.9121e-01, -2.9412e-01, -5.7475e-02, -1.8747e-01,\n","         1.6045e-01,  1.0385e-01,  5.1178e-01,  1.2840e-01, -3.3281e-01,\n","         2.6939e-01, -3.5175e-01,  6.2651e-01,  2.9008e-01,  3.7304e-01,\n","         4.0544e-02, -3.6665e-01, -1.0528e-01, -6.6002e-01, -6.6317e-02,\n","         5.0627e-01,  2.0558e-01, -1.8909e-02, -5.6063e-01, -3.2331e-01,\n","        -3.5732e-01, -1.2919e-01,  1.5296e-01, -7.1057e-02,  9.9959e-02,\n","         6.0830e-02,  4.0220e-01, -1.4335e-01, -4.6526e-01, -7.8211e-02,\n","         5.6127e-01, -4.8189e-01,  5.5877e-02,  6.0063e-02,  7.7121e-01,\n","        -5.2509e-01, -3.7105e-01,  1.6058e-01, -3.5978e-01,  1.8269e-01,\n","        -2.1774e-01, -7.3613e-01, -2.9084e-01, -4.4551e-02,  3.8114e-01,\n","        -1.4108e-01, -1.8333e-01,  3.7169e-01, -1.9730e-01, -2.2467e-01,\n","         3.1620e-01,  8.1412e-02, -8.0367e-01, -2.2259e-01, -2.4526e-01,\n","         4.8726e-01,  1.5435e-01, -3.4813e-02,  2.3038e-01,  5.2597e-01,\n","         5.6235e-02,  2.4087e-01,  9.2098e-02,  2.9834e-02, -1.2290e-01,\n","        -5.6653e-01, -8.5997e-01, -3.8629e-02, -3.5260e-01, -3.0995e-01,\n","         1.4549e-01,  8.1988e-04,  8.5296e-02, -1.5438e-01,  1.9446e-01,\n","         4.5667e-02,  3.7399e-01,  6.2339e-01,  2.4329e-01,  2.7512e-01,\n","         1.7586e+00,  3.4216e-02, -1.6764e-01,  1.3634e-01,  1.0513e-01,\n","        -3.2869e-01,  2.2288e-01,  1.1257e-01, -1.4878e-02, -2.9367e-02,\n","         1.0413e-01,  2.7607e-01, -4.6038e-01,  5.1864e-02,  1.6174e-01,\n","        -2.7844e-01, -9.1567e-02, -4.5173e-02, -8.2913e-02, -3.3233e-01,\n","         1.0870e-01, -3.9585e-01, -3.3200e-01, -1.2790e-01,  5.4628e-01,\n","        -4.0196e-01, -6.4199e-03,  2.4775e-01, -8.4103e-01, -3.4053e-02,\n","         1.2032e-01, -4.1636e-02,  5.1895e-01, -2.6675e-01, -1.8235e-01,\n","        -4.1976e-03, -2.0791e-01,  1.1761e-01,  3.7804e-01,  7.7061e-01,\n","         5.1430e-01,  3.8859e-01,  6.6335e-01,  1.9845e-01, -9.0171e-02,\n","        -7.9311e-02,  1.2066e-01, -2.5846e-02, -4.3176e-02,  1.0805e-01,\n","         4.9527e-01,  3.9891e-03, -1.1265e-01,  1.4894e-01,  5.3257e-01,\n","        -3.1347e-01,  4.0668e-01, -4.0542e-02, -1.6759e-01,  4.2687e-01,\n","        -2.0221e-01, -6.2603e-01,  5.6268e-02,  2.0112e-01,  1.2048e-01,\n","         4.9785e-01, -5.2186e-01, -1.8035e-01, -4.9756e-01, -3.1150e-01,\n","        -3.8850e-01, -2.7542e-01,  5.1444e-02,  1.3145e-02,  6.0204e-01,\n","         9.9091e-02, -1.6328e+00, -3.6475e-01,  3.4421e-01,  6.6319e-01,\n","        -3.5724e-02,  8.3642e-02,  8.0001e-02,  6.8445e-01,  5.5394e-01,\n","         9.9430e-02, -1.3024e-01, -7.7788e-02,  2.3433e-01, -7.2924e-01,\n","        -1.1271e-01, -5.5649e-02, -7.4247e-01,  1.3555e-01,  3.0328e-01,\n","        -1.0663e-01,  1.8475e-01, -8.1355e-01, -5.1386e-02, -3.0962e-01]), 'individual': tensor([-0.5919,  0.4996, -0.1013, -0.0384,  0.5315,  0.3154,  0.0407,  0.3487,\n","         0.1758, -1.5649, -0.0223,  0.0422, -0.6128, -0.1498,  0.1333,  0.2608,\n","         0.2561,  0.1024,  0.0208, -0.4170,  0.3583,  0.1736,  0.0170,  0.2202,\n","         0.3492, -0.2119, -0.2271,  0.4122, -0.0424, -0.2655, -0.3396,  0.2297,\n","        -0.2639, -0.8021, -1.0365, -0.0150,  0.5067, -0.0693, -0.2810, -0.1218,\n","        -0.1231, -0.0136,  0.1440,  0.3576,  0.1250,  0.1805,  0.0282,  0.3555,\n","        -0.0865,  0.4047,  0.1797,  0.3213,  0.3495, -0.1380, -0.2450,  0.5452,\n","        -0.4139,  0.0233,  0.0903,  0.2023,  0.5467,  0.2370, -0.5445, -0.0980,\n","         0.2448,  0.2104, -0.4666,  0.5677, -0.0973,  0.5768, -0.1165, -0.4122,\n","        -0.1748, -0.1476, -0.5380,  0.2211, -0.1442, -0.2207, -0.1348, -0.4385,\n","        -0.1262,  0.2569, -0.3977, -0.1855, -0.0473, -0.1665, -0.0378, -0.6772,\n","         0.2151,  0.3365, -0.2194,  0.3013, -0.1382, -0.1026,  0.9100, -0.3145,\n","        -0.3898,  0.5026, -0.0298, -0.1166, -0.4385, -0.2572, -0.2840, -0.2958,\n","         0.1276, -0.1045,  0.3685, -0.4682, -0.3742,  0.0353, -0.2055,  0.2248,\n","         0.0445,  0.0034, -0.5004,  0.1721, -0.0277,  0.1609, -0.2725,  0.0567,\n","         0.0035,  0.9370,  0.4067,  0.3213,  0.4067,  0.3549, -0.3560,  0.2039,\n","        -0.5889,  0.3230, -0.4522, -0.0044,  0.0549, -0.0184, -0.0113,  0.0487,\n","        -0.3885,  0.1801, -0.1202, -0.1417, -0.4184,  0.2435,  0.0177, -0.0491,\n","        -0.2884, -0.2934, -0.1019,  0.3372, -0.0648, -0.0217,  0.1716, -0.2852,\n","        -0.0657, -0.2484, -0.1569,  0.1119, -0.3282,  0.0439, -0.5076, -0.3529,\n","        -0.0609, -0.2380,  0.0453, -0.0499,  0.3376,  0.3087, -0.0537,  0.2038,\n","         0.0366,  0.1041,  0.3805, -0.2444, -0.3404,  0.2923,  0.1008, -0.4726,\n","         0.4258,  0.4067, -0.2008,  0.4849,  0.1010, -0.6109, -0.0770, -0.3141,\n","        -0.2175,  0.2140, -0.0711, -0.3667,  0.0731,  0.0342, -0.0174, -0.5552,\n","        -0.0348,  0.1450,  0.0531, -0.0638, -0.0782, -0.2918, -0.0995, -0.3907,\n","         0.2884, -0.3134, -0.3487, -0.4561,  0.2591,  0.1033, -0.4640,  0.1799,\n","        -0.2268,  0.2442,  0.6430,  0.0458, -0.0567, -0.4973, -0.0486,  0.1467,\n","         0.4694,  0.3855,  0.4142,  0.5205, -1.0366, -0.3282,  0.1147,  0.1972,\n","         0.0392, -0.0591, -0.2215,  0.1425, -0.3416,  0.4442, -0.5113, -0.0259,\n","         0.2689,  0.0733,  0.0231,  0.4598, -0.2407,  0.0980, -0.5156,  0.3591,\n","         0.2530,  0.2731,  0.5989,  0.0527, -1.1709, -0.3193, -0.0244, -0.0187,\n","         0.1822,  0.1830, -0.0789, -0.2473,  0.2417,  0.1484,  0.4214, -0.0347,\n","         0.3123,  0.1963, -0.1598,  0.3273,  0.4173, -0.4756,  0.3847,  0.1442,\n","         0.1128, -0.1105, -0.3585,  0.1535, -0.0080,  0.0293, -0.0188,  0.0877,\n","         0.1439,  0.8165, -0.2156, -0.0921, -2.1012, -0.0772,  0.2066, -0.1686,\n","         0.3131, -0.7512,  0.0133,  0.5306, -0.2336,  0.5480,  0.2856,  0.2328,\n","         0.1283, -0.1556, -0.2317, -0.2918, -0.3045, -0.4453,  0.4152, -0.1266,\n","        -0.2069, -0.0517,  0.0866, -0.4446])}\n"]}]},{"cell_type":"markdown","source":["Now that you have loaded the pretrained embeddings for the sample words, let's check if the model can capture the similarity of words by finding the distance between words:\n"],"metadata":{"id":"yO2tPaOdUBJ8"}},{"cell_type":"code","source":["import numpy as np\n","\n","def find_similar_words(target_word, embedding_dict, top_k=2):\n","    if target_word not in embedding_dict:\n","        return f\"Word '{target_word}' not found in embeddings.\"\n","\n","    target_vector = embedding_dict[target_word]\n","    similarities = {}\n","\n","    for word, vector in embedding_dict.items():\n","        if word == target_word:\n","            continue\n","        similarity = np.dot(target_vector, vector) / (np.linalg.norm(target_vector) * np.linalg.norm(vector))\n","        similarities[word] = similarity\n","\n","    sorted_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n","    return [word for word, _ in sorted_words[:top_k]]"],"metadata":{"id":"adtnI7T0WoRb","executionInfo":{"status":"ok","timestamp":1753739425074,"user_tz":420,"elapsed":3,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":90,"outputs":[]},{"cell_type":"code","source":["# Call the function to find similar words\n","target_word = \"small\"\n","top_k=2\n","similar_words = find_similar_words(target_word, embedding_dict_Glove6B, top_k)\n","\n","# Print the similar words\n","print(\"{} most similar words to {}:\".format(top_k,target_word) ,similar_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXqPcElkT_r-","executionInfo":{"status":"ok","timestamp":1753739425914,"user_tz":420,"elapsed":9,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"5685a785-62e1-4924-8d9a-7204fe8e1504"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["2 most similar words to small: ['tiny', 'big']\n"]}]},{"cell_type":"markdown","source":["It can be seen the pretrained GloVe model does quite good job capturing the similarity of words.\n"],"metadata":{"id":"SoSqTMtRXCOy"}},{"cell_type":"markdown","source":["# Train a word2vec model from gensim\n","\n","Here's a simple hands-on exercise to train a word2vec model using `gensim` library.\n","In this example, you have a small corpus consisting of four sentences.\n","\n","### Prepare your corpus:\n"],"metadata":{"id":"eWGybKuoXQgm"}},{"cell_type":"code","source":["sentences = [\n","    [\"I\", \"like\", \"to\", \"eat\", \"pizza\"],\n","    [\"Pizza\", \"is\", \"my\", \"favorite\", \"food\"],\n","    [\"I\", \"enjoy\", \"eating\", \"Pasta\"],\n","]"],"metadata":{"id":"QbCpXoWgUgqN","executionInfo":{"status":"ok","timestamp":1753739429467,"user_tz":420,"elapsed":3,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["sentences = [[word.lower() for word in sentence] for sentence in sentences]\n","print(sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0HO3Zuo_Xp4b","executionInfo":{"status":"ok","timestamp":1753739430348,"user_tz":420,"elapsed":15,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"20f02cc7-931f-4ed9-e107-8bda9436a2ce"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["[['i', 'like', 'to', 'eat', 'pizza'], ['pizza', 'is', 'my', 'favorite', 'food'], ['i', 'enjoy', 'eating', 'pasta']]\n"]}]},{"cell_type":"markdown","source":["The `size` parameter specifies the dimensionality of the word embeddings (in this case, 100). The `window` parameter determines the size of the context window. The `min_count` parameter sets the minimum frequency of a word to be included in the training process. Finally, the `workers` parameter controls the number of threads used for training.\n"],"metadata":{"id":"JakAKm0pYLgk"}},{"cell_type":"code","source":["from gensim.models import word2vec\n","\n","# Create an instance of Word2Vec model\n","w2v_model = Word2Vec(sentences, vector_size=100, window=3, min_count=1, workers=4)"],"metadata":{"id":"mUc5tpTzYAU8","executionInfo":{"status":"ok","timestamp":1753739431916,"user_tz":420,"elapsed":50,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":["Create vocab from sentences:\n"],"metadata":{"id":"8bOOZxUEYfKk"}},{"cell_type":"markdown","source":["In the line:\n","\n","```python\n","w2v_model.build_vocab(sentences, progress_per=10000)\n","```\n","\n","### 🧾 `progress_per=10000` means:\n","\n","The model will **print progress updates** every **10,000 sentences** while building the vocabulary.\n","\n","---\n","\n","### 🛠️ Purpose:\n","\n","* Helps track progress during **vocab building**, especially with large datasets.\n","* Useful for debugging or monitoring long-running processes.\n","\n","---\n","\n","### ✅ Example:\n","\n","If you have 100,000 sentences and `progress_per=10000`, you'll see 10 progress updates like:\n","\n","```\n","PROGRESS: at sentence #10000, processed 120000 words...\n","```\n","\n","---\n","\n","**Note:** This parameter is specific to **Gensim's Word2Vec** (or similar models), not PyTorch or TensorFlow.\n"],"metadata":{"id":"MMbTrVlhYxPq"}},{"cell_type":"code","source":["w2v_model.build_vocab(sentences, progress_per=1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GkZj57oYYdWO","executionInfo":{"status":"ok","timestamp":1753739432547,"user_tz":420,"elapsed":9,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"5da44a84-ab8d-43a0-e343-4c2e4e076beb"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"]}]},{"cell_type":"markdown","source":["Train the model:\n"],"metadata":{"id":"k-H2b1LQY4H8"}},{"cell_type":"code","source":["w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfcTWxC6Yx2m","executionInfo":{"status":"ok","timestamp":1753739432979,"user_tz":420,"elapsed":101,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"36a2a677-a097-4aaf-8a58-8a2c6f08a1d0"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"]},{"output_type":"execute_result","data":{"text/plain":["(55, 420)"]},"metadata":{},"execution_count":96}]},{"cell_type":"markdown","source":["That's it! You've trained a word2vec model using the `gensim` library. You can now access the word embeddings using `model.wv` and explore various operations such as finding similar words, calculating word similarities, and more.\n"],"metadata":{"id":"bIbBv5YkZL7R"}},{"cell_type":"markdown","source":["Use the trained model to find similar words to \"pizza\" and calculate the similarity between \"pizza\" and \"pasta\".\n"],"metadata":{"id":"gTndXluOZOZj"}},{"cell_type":"code","source":["# Finding similar words\n","similar_words = w2v_model.wv.most_similar(\"pizza\")\n","print(\"Similar words to 'pizza':\", similar_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLvoVl6NZGXi","executionInfo":{"status":"ok","timestamp":1753739433461,"user_tz":420,"elapsed":29,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"c7d09506-1147-4802-e6de-f008ba8df305"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["Similar words to 'pizza': [('to', 0.17027318477630615), ('is', 0.13898280262947083), ('my', 0.035433270037174225), ('like', 0.00451968889683485), ('pasta', -0.005902299657464027), ('i', -0.027743974700570107), ('favorite', -0.028113720938563347), ('eat', -0.04430948570370674), ('food', -0.06873457878828049), ('enjoy', -0.1732126623392105)]\n"]}]},{"cell_type":"code","source":["# Calculating word similarity\n","similarity = w2v_model.wv.similarity(\"pizza\", \"pasta\")\n","print(\"Similarity between 'pizza', and 'pasta':\", similarity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQx9drSTZdrA","executionInfo":{"status":"ok","timestamp":1753739433705,"user_tz":420,"elapsed":78,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"0bdc3bd4-ce80-4b8b-88b6-cdd3e4ae96d0"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity between 'pizza', and 'pasta': -0.00590231\n"]}]},{"cell_type":"markdown","source":["The word embeddings obtained from the model would be more meaningful and informative with larger and more diverse training data.\n"],"metadata":{"id":"0EO2UbGfZ0mE"}},{"cell_type":"markdown","source":["Use the trained model to create a PyTorch embedding layer (just like what you did with the pretrained GloVe model) and use it in any task as an embedding layer.\n"],"metadata":{"id":"Ui7nLVi7Z34w"}},{"cell_type":"code","source":["# Extract word vectors and create word-to-index mapping\n","word_vectors = w2v_model.wv\n","\n","# a dictionary to map words to their index in vocab\n","word_to_index = {word : index for index, word in enumerate(word_vectors.index_to_key)}\n","\n","# Create an instance of nn.Embedding and load it with the trained vectors\n","embedding_dim = w2v_model.vector_size\n","embedding = torch.nn.Embedding(len(word_vectors.index_to_key), embedding_dim)\n","embedding.weight.data.copy_(torch.from_numpy(word_vectors.vectors))\n","\n","# Example usage: get the embedding for a word\n","word = \"pizza\"\n","word_index = word_to_index[word]\n","word_embedding = embedding(torch.LongTensor([word_index]))\n","print(f\"Word: {word}, Embedding: {word_embedding.detach().numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgDRv23cZve_","executionInfo":{"status":"ok","timestamp":1753739434505,"user_tz":420,"elapsed":21,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"c19e8529-7b0e-4abe-a15e-00062a5b4e51"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["Word: pizza, Embedding: [[-0.00714092  0.00124133 -0.00717793 -0.00224098  0.00372044  0.00583255\n","   0.00120101  0.00210401 -0.00411258  0.00722417 -0.00630454  0.00464709\n","  -0.00821901  0.00203745 -0.00497656 -0.00424712 -0.00310588  0.00565446\n","   0.00579693 -0.00497813  0.00077411 -0.00849433  0.00781365  0.00925739\n","  -0.00274148  0.00080058  0.00074548  0.00547892 -0.00860763  0.00058273\n","   0.00687327  0.00223279  0.0011247  -0.00932057  0.00847972 -0.00626165\n","  -0.00299271  0.00349315 -0.0007744   0.00141046  0.00178483 -0.00682816\n","  -0.00972361  0.00903822  0.00620081 -0.00691076  0.00340142  0.0002056\n","   0.00475387 -0.00712     0.00402757  0.0043473   0.00995535 -0.0044746\n","  -0.00139121 -0.00732087 -0.00969911 -0.00908164 -0.00102246 -0.00650654\n","   0.0048497  -0.00616394  0.00252445  0.00073935 -0.00339426 -0.0009791\n","   0.0099768   0.00914695 -0.00446548  0.00908081 -0.00564203  0.00593325\n","  -0.00309734  0.00343278  0.00301738  0.00689681 -0.00237353  0.00877608\n","   0.00758863 -0.00954776 -0.00800817 -0.00764088  0.00292232 -0.00279256\n","  -0.00692898 -0.00813168  0.00831193  0.00198979 -0.00932875 -0.00479274\n","   0.00313295 -0.00471185  0.00528117 -0.00423292  0.00264694 -0.00804584\n","   0.00621066  0.00481859  0.00078948  0.0030138 ]]\n"]}]},{"cell_type":"markdown","source":["# Text classification using pretrained word embeddings\n","\n","You are ready to use the embeddings in a task, then. Let's use the pretrained embeddings to classify text data into topics:\n"],"metadata":{"id":"0WwYyQeQbLWY"}},{"cell_type":"markdown","source":["First, you must build vocab from the pretrained GloVe:\n"],"metadata":{"id":"PIWdvp3abNew"}},{"cell_type":"code","source":["from torchtext.vocab import GloVe, vocab\n","\n","# Build vocab from glove_vectors\n","# vocab(ordered_dict: Dict, min_freq: int = 1, specials: Optional[List[str]] = None)\n","vocab = vocab(glove_vectors_6B.stoi, 0, specials = ('<unk>', '<pad>'))\n","vocab.set_default_index(vocab[\"<unk>\"])"],"metadata":{"id":"7eAwt4g6bC5s","executionInfo":{"status":"ok","timestamp":1753739463963,"user_tz":420,"elapsed":40,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["vocab([\"<unk>\", \"Hello\", \"hello\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTSuKQYsbqFy","executionInfo":{"status":"ok","timestamp":1753739464338,"user_tz":420,"elapsed":15,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"c175cfdc-0017-4781-a31e-90b08ae0a489"},"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 0, 13077]"]},"metadata":{},"execution_count":101}]},{"cell_type":"markdown","source":["Next, you need to tokenize text. For this you can use pretrained tokenizers from torch:\n"],"metadata":{"id":"oJkcR73pb4h_"}},{"cell_type":"code","source":["# Define tokenizer\n","tokenizer = get_tokenizer(\"basic_english\")"],"metadata":{"id":"EU-M-6xnbw1v","executionInfo":{"status":"ok","timestamp":1753739465718,"user_tz":420,"elapsed":4,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":["Create splits from AG_NEWS() dataset for training, validation and test:\n"],"metadata":{"id":"8nxelqPPcAE0"}},{"cell_type":"code","source":["# Split the dataset into training and testing iterators.\n","train_iter, test_iter = AG_NEWS()\n","\n","# Convert the training and testing iterators to map-style datasets.\n","train_dataset = to_map_style_dataset(train_iter)\n","test_dataset = to_map_style_dataset(test_iter)\n","\n","# Determine the number of samples to be used for training and validation (5% for validation).\n","num_train = int(len(train_dataset)*0.85)\n","\n","# Randomly split the training dat aset into training and validation datasets using `random_split`.\n","# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.\n","split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])"],"metadata":{"id":"B_H4Cc24b9kX","executionInfo":{"status":"ok","timestamp":1753739468991,"user_tz":420,"elapsed":1845,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":["Define the class labels:\n"],"metadata":{"id":"PZXHNN6Pcktl"}},{"cell_type":"code","source":["# define class labels\n","ag_news_label = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}"],"metadata":{"id":"I-uCqg51chV7","executionInfo":{"status":"ok","timestamp":1753739470891,"user_tz":420,"elapsed":2,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["num_class = len(set([label for (label, text) in train_iter]))"],"metadata":{"id":"hmOcXqZ5cyJk","executionInfo":{"status":"ok","timestamp":1753739473645,"user_tz":420,"elapsed":2063,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["num_class"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMdQNoxkc7OO","executionInfo":{"status":"ok","timestamp":1753739473665,"user_tz":420,"elapsed":22,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"faf97555-b947-4993-eadb-f729dd6be88e"},"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":106}]},{"cell_type":"markdown","source":["Collate data in batches:\n"],"metadata":{"id":"267frvRhdBxp"}},{"cell_type":"code","source":["def text_pipeline(x):\n","    x=x.lower()# you need this as your vocab is in lower case\n","    return vocab(tokenizer(x))"],"metadata":{"id":"W9wLJzANc9Bm","executionInfo":{"status":"ok","timestamp":1753739475213,"user_tz":420,"elapsed":3,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["def label_pipeline(x):\n","  return int(x) - 1"],"metadata":{"id":"BvU8IW-CdKAg","executionInfo":{"status":"ok","timestamp":1753739476185,"user_tz":420,"elapsed":84,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["# create label, text and offset for each batch of data\n","# text is the concatenated text for all text data in the batch\n","# you need to have the offsets(the end of text index) for later when you separate texts and predict their label\n","def collate_batch(batch):\n","  label_list, text_list, offsets = [], [], [0]\n","\n","  for _label, _text in batch:\n","    label_list.append(label_pipeline(_label))\n","    processed_text =  torch.tensor(text_pipeline(_text), dtype=torch.int64)\n","    text_list.append(processed_text)\n","    offsets.append(processed_text.size(0))\n","\n","  label_list = torch.tensor(label_list, dtype=torch.int64)\n","  offsets = torch.tensor(offsets).cumsum(dim=0)\n","  text_list = torch.cat(text_list)\n","\n","  return label_list.to(device), text_list.to(device), offsets.to(device)"],"metadata":{"id":"jG0AemVKdO04","executionInfo":{"status":"ok","timestamp":1753739476364,"user_tz":420,"elapsed":3,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":["Create data loaders for train, validation and test splits:\n"],"metadata":{"id":"QgHP8gsReZ0r"}},{"cell_type":"code","source":["BATCH_SIZE=64"],"metadata":{"id":"9YugNu17eXUX","executionInfo":{"status":"ok","timestamp":1753739477766,"user_tz":420,"elapsed":2,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n","valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)"],"metadata":{"id":"C0v_a7CiemZU","executionInfo":{"status":"ok","timestamp":1753739478645,"user_tz":420,"elapsed":7,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["label, text, offsets = next(iter(train_dataloader))\n","print(label, text, offsets)\n","label.shape, text.shape, offsets.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bW87i08se52i","executionInfo":{"status":"ok","timestamp":1753739504005,"user_tz":420,"elapsed":30,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"980c7105-9a7f-4582-ae96-ff54ace4c378"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2, 2, 0, 2, 3, 2, 1, 2, 1, 3, 3, 2, 1, 3, 3, 0, 1, 0, 1, 3, 1, 0, 3, 0,\n","        3, 2, 0, 0, 0, 1, 3, 2, 2, 3, 2, 2, 3, 3, 0, 2, 3, 1, 2, 1, 1, 0, 3, 3,\n","        0, 1, 3, 0, 0, 2, 0, 2, 0, 0, 2, 1, 1, 1, 3, 0]) tensor([7321,   84,    6,  ...,   15,  187,    4]) tensor([   0,   39,   84,  130,  164,  216,  253,  302,  345,  391,  426,  470,\n","         512,  546,  591,  632,  711,  742,  785,  829,  884,  914,  949,  984,\n","        1015, 1069, 1106, 1142, 1280, 1320, 1362, 1411, 1457, 1508, 1536, 1576,\n","        1623, 1662, 1810, 1850, 1916, 1953, 1985, 2075, 2104, 2143, 2186, 2221,\n","        2271, 2316, 2354, 2400, 2440, 2491, 2542, 2579, 2633, 2661, 2707, 2740,\n","        2783, 2834, 2865, 2896, 2957])\n"]},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([64]), torch.Size([2957]), torch.Size([65]))"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","source":["Create the classifier model:\n"],"metadata":{"id":"VPx2f9mFhsfg"}},{"cell_type":"markdown","source":["Here's a **simple explanation** of your `TextClassificationModel` class for a **newbie** in PyTorch:\n","\n","---\n","\n","### 🔍 What is it?\n","\n","This is a **text classification model** — it takes in a piece of text (like a sentence), and tries to **predict a label** for it (e.g., spam or not spam, positive or negative, etc.).\n","\n","It uses **pre-trained word embeddings** from **GloVe** to understand the meaning of words.\n","\n","---\n","\n","### 🧱 What's inside the model?\n","\n","1. **`self.embedding`**\n","\n","   * Turns each word into a vector using **pretrained GloVe embeddings**.\n","   * `freeze=True` means we **don’t update** these vectors during training.\n","\n","2. **`self.fc` (fully connected layer)**\n","\n","   * A simple linear layer that maps the averaged word vector to a prediction.\n","   * `embed_dim` = size of word vectors; `num_class` = number of labels.\n","\n","3. **`init_weights()`**\n","\n","   * Initializes weights to small random values (and biases to zero).\n","   * Helps the model start with reasonable values.\n","\n","---\n","\n","### ⚙️ How it works (`forward()` method):\n","\n","1. **Input:**\n","\n","   * `text`: a long list of word indices from all texts (sentences) in the batch.\n","   * `offsets`: positions in `text` where each sentence starts.\n","\n","2. **Steps:**\n","\n","   * `self.embedding(text)` converts words into vectors.\n","   * Then, for each sentence:\n","\n","     * It finds the words for that sentence using `offsets`.\n","     * It **averages the word vectors** to get one vector per sentence.\n","\n","3. **Final step:**\n","\n","   * The average vector is passed through the linear layer (`fc`) to get predictions.\n","\n","---\n","\n","### ✨ In plain words:\n","\n","> The model reads each sentence, understands the meaning of its words using GloVe embeddings, averages those meanings, and makes a prediction like \"positive\" or \"negative\".\n","\n","---"],"metadata":{"id":"yaV0s-BpSZCn"}},{"cell_type":"code","source":["class TextClassificationModel(nn.Module):\n","  def __init__(self, vocab_size, embed_dim, num_class):\n","    super(TextClassificationModel, self).__init__()\n","    self.embedding = torch.nn.Embedding.from_pretrained(glove_vectors_6B.vectors, freeze=True)\n","    self.fc = nn.Linear(embed_dim, num_class)\n","    self.init_weights()\n","\n","  def init_weights(self):\n","    initrange=0.5\n","    self.embedding.weight.data.uniform_(-initrange, initrange)\n","    self.fc.weight.data.uniform_(-initrange, initrange)\n","    self.fc.bias.data.zero_()\n","\n","  def forward(self, text, offsets):\n","    embedded = self.embedding(text)\n","    # you get the average of word embeddings in the text\n","    means = []\n","    for i in range(1, len(offsets)):\n","      text_tmp = embedded[offsets[i-1]:offsets[i]]\n","      means.append(text_tmp.mean(0))\n","\n","    return self.fc(torch.stack(means))"],"metadata":{"id":"WzccmJsGgDZd","executionInfo":{"status":"ok","timestamp":1753739506593,"user_tz":420,"elapsed":4,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":["Define an evaluate function to calculate the accuracy of model:\n"],"metadata":{"id":"5ncTuZpTS8XV"}},{"cell_type":"code","source":["def evaluate(dataloader):\n","  model.eval()\n","  total_acc, total_count = 0, 0\n","\n","  with torch.no_grad():\n","    for idx, (label, text, offsets) in enumerate(dataloader):\n","      predicted_label = model(text, offsets)\n","\n","      total_acc += (predicted_label.argmax(1) == label).sum().item()\n","      total_count += label.size(0)\n","\n","  return total_acc/total_count"],"metadata":{"id":"M2_wQ6PCjGuK","executionInfo":{"status":"ok","timestamp":1753739507865,"user_tz":420,"elapsed":2,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":["Create an instance of the model and check its prediction power before training:\n"],"metadata":{"id":"0zN6_f9_TiPR"}},{"cell_type":"code","source":["# Define hyperparameters\n","vocab_size = len(vocab)\n","embedding_dim = 300\n","# Initialize the model\n","model = TextClassificationModel(vocab_size, embedding_dim, num_class).to(device)"],"metadata":{"id":"xAOIi8SsTfql","executionInfo":{"status":"ok","timestamp":1753739510218,"user_tz":420,"elapsed":1020,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":116,"outputs":[]},{"cell_type":"code","source":["evaluate(test_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9uoVNlWTxan","executionInfo":{"status":"ok","timestamp":1753739521152,"user_tz":420,"elapsed":1225,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"2f0553df-a6f4-4797-8468-934e6d30d4d2"},"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2557894736842105"]},"metadata":{},"execution_count":118}]},{"cell_type":"markdown","source":["Not good! Let's train the model:\n"],"metadata":{"id":"42H7uibA3xcC"}},{"cell_type":"code","source":["def train_TextClassification(model,dataloader,criterion,optimizer,epochs=10):\n","\n","    cum_loss_list=[]\n","    acc_epoch=[]\n","    acc_old=0\n","\n","    for epoch in tqdm(range(1, EPOCHS + 1)):\n","        model.train()\n","        cum_loss=0\n","        for idx, (label, text, offsets) in enumerate(train_dataloader):\n","            means = []\n","            optimizer.zero_grad()\n","\n","\n","            predicted_label = model(text, offsets)\n","\n","            loss = criterion(predicted_label, label)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","            optimizer.step()\n","            cum_loss+=loss.item()\n","\n","        print(cum_loss/len(train_dataloader))\n","        cum_loss_list.append(cum_loss/len(train_dataloader))\n","        accu_val = evaluate(valid_dataloader)\n","        print(accu_val)\n","        acc_epoch.append(accu_val)\n","\n","        if accu_val > acc_old:\n","          acc_old= accu_val\n","          torch.save(model.state_dict(), 'my_model.pth')\n","\n","    return model,cum_loss_list,acc_epoch"],"metadata":{"id":"bNW5KxK8Tz2M","executionInfo":{"status":"ok","timestamp":1753739522502,"user_tz":420,"elapsed":11,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["# Define hyperparameters\n","LR=0.1\n","EPOCHS=10\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n","\n","model, cum_loss_list, acc_epoch = train_TextClassification(model, train_dataloader, criterion, optimizer, EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZThIXz25gAz","executionInfo":{"status":"ok","timestamp":1753739729402,"user_tz":420,"elapsed":205800,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"220b6851-af1f-4aca-c633-08f002daf95d"},"execution_count":120,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["1.3340139033803378\n","0.44816666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 1/10 [00:27<04:07, 27.56s/it]"]},{"output_type":"stream","name":"stdout","text":["1.2268108530355666\n","0.5327222222222222\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 2/10 [00:44<02:51, 21.44s/it]"]},{"output_type":"stream","name":"stdout","text":["1.1560439447237827\n","0.5703333333333334\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 3/10 [01:02<02:18, 19.82s/it]"]},{"output_type":"stream","name":"stdout","text":["1.1027557368634486\n","0.5964444444444444\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 4/10 [01:20<01:54, 19.11s/it]"]},{"output_type":"stream","name":"stdout","text":["1.0612701692126476\n","0.6167777777777778\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 5/10 [01:37<01:32, 18.43s/it]"]},{"output_type":"stream","name":"stdout","text":["1.0284058854750437\n","0.6281111111111111\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 6/10 [01:55<01:12, 18.16s/it]"]},{"output_type":"stream","name":"stdout","text":["1.0015672590382574\n","0.6374444444444445\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 7/10 [02:23<01:03, 21.25s/it]"]},{"output_type":"stream","name":"stdout","text":["0.9794434735661319\n","0.6435555555555555\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 8/10 [02:40<00:39, 19.95s/it]"]},{"output_type":"stream","name":"stdout","text":["0.9608542786413334\n","0.6506666666666666\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 9/10 [02:58<00:19, 19.36s/it]"]},{"output_type":"stream","name":"stdout","text":["0.9450794564959695\n","0.6562777777777777\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [03:25<00:00, 20.58s/it]\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","def plot(COST, ACC):\n","  fig, ax1 = plt.subplots()\n","  color = 'tab:red'\n","  ax1.plot(COST, color=color)\n","  ax1.set_xlabel('epoch')\n","  ax1.set_ylabel('total_loss', color=color)\n","  ax1.tick_params(axis='y', color=color)\n","\n","  ax2 = ax1.twinx()\n","  color = 'tab:blue'\n","  ax2.set_ylabel('accuracy', color=color)\n","  ax2.plot(ACC, color=color)\n","  ax2.tick_params(axis='y', color=color)\n","  fig.tight_layout()\n","\n","  plt.show()"],"metadata":{"id":"NoGCvEjx6Iw1","executionInfo":{"status":"ok","timestamp":1753739733738,"user_tz":420,"elapsed":42,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["print(cum_loss_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNGkmXQD9YoF","executionInfo":{"status":"ok","timestamp":1753739757137,"user_tz":420,"elapsed":16,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"69504045-a191-4d06-e459-a2b07d567df6"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.3340139033803378, 1.2268108530355666, 1.1560439447237827, 1.1027557368634486, 1.0612701692126476, 1.0284058854750437, 1.0015672590382574, 0.9794434735661319, 0.9608542786413334, 0.9450794564959695]\n"]}]},{"cell_type":"code","source":["print(acc_epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EpT1ERun9d8r","executionInfo":{"status":"ok","timestamp":1753739758011,"user_tz":420,"elapsed":9,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"e8842ffb-ac91-4674-8f34-0d0f02be615b"},"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.44816666666666666, 0.5327222222222222, 0.5703333333333334, 0.5964444444444444, 0.6167777777777778, 0.6281111111111111, 0.6374444444444445, 0.6435555555555555, 0.6506666666666666, 0.6562777777777777]\n"]}]},{"cell_type":"code","source":["plot(cum_loss_list, acc_epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":486},"id":"qoejlAXl849V","executionInfo":{"status":"ok","timestamp":1753739767453,"user_tz":420,"elapsed":511,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"03e6295c-712b-4307-c3c2-3e84fd07cb1f"},"execution_count":125,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["Finally, evaluate the model on test data:\n"],"metadata":{"id":"SLQ-qixxCWOh"}},{"cell_type":"code","source":["evaluate(test_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZTGcT9y8-UW","executionInfo":{"status":"ok","timestamp":1753739792446,"user_tz":420,"elapsed":1378,"user":{"displayName":"Muhammad Abu Bakar","userId":"14660569120433860905"}},"outputId":"ae5fdb98-e470-4aff-b48a-ffbf78ff4769"},"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6444736842105263"]},"metadata":{},"execution_count":126}]}]}